{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining individual coverage data into a mean-normalized coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "\n",
    "+ for the PanelofNormals, create a coverage file for each PON bam and each chromosome\n",
    "+ Pon bams should optimally not contain CNV or there should be a lot of them to reduce the std\n",
    "+ put all the files into a big matrix and normalize coverages and produce an average coverage (+ std) for the exonic space\n",
    "+ compare the tumor samples against that PONcoverage to get differences in CNV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### have to look at the Kenichi-CNV-graphs to identify the samples from FDAH1 without CNVs in the normals\n",
    "+ [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "### alternative approach\n",
    "+ get all samples and remove the outliers from std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T11:35:06.741785Z",
     "start_time": "2020-09-28T11:35:06.738451Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the paths\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "testdata = f\"{home}/Dropbox/Icke/Work/somVar/testdata\"\n",
    "tooldata = f\"{home}/Dropbox/Icke/Work/somVar/tooldata\"\n",
    "shell_path = \"../shell\"\n",
    "static_path = f\"{home}/Dropbox/Icke/Work/static\"\n",
    "bed_path = f\"{static_path}/bed_files/SureSelect/hg38\"\n",
    "\n",
    "cnvdata = f\"{tooldata}/myCNVdata/\"\n",
    "bedCov_path = f\"{cnvdata}/bedCov\"\n",
    "bedCov_path = f\"{home}/mount/scratch/develop/PONcoverage/bedCov\"\n",
    "output_path = f\"{cnvdata}/output/PONcoverage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T11:35:08.218157Z",
     "start_time": "2020-09-28T11:35:08.212994Z"
    }
   },
   "outputs": [],
   "source": [
    "bedCov_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T11:35:11.733842Z",
     "start_time": "2020-09-28T11:35:11.533103Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{bedCov_path}/009_B.chr5.bedCov', sep='\\t', compression=\"gzip\")\n",
    "test[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all the normal samples from the PON list into df for normalization and averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T11:35:33.092783Z",
     "start_time": "2020-09-28T11:35:30.006237Z"
    }
   },
   "outputs": [],
   "source": [
    "# try with pd merge\n",
    "import os\n",
    "def combine_coverage(PONcov_path, chrom, sample_list):\n",
    "    cov_df = pd.DataFrame(columns=['ExonPos', 'Pos'])\n",
    "    for sample in sample_list:\n",
    "        file = os.path.join(PONcov_path, f\"{sample}.{chrom}.bedCov\")\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        print(f\"Reading {sample} from {file}.\")\n",
    "        df = pd.read_csv(file, sep='\\t', compression='gzip').loc[:,['Pos', 'ExonPos', 'Coverage']].rename(columns={'Coverage':sample})\n",
    "        cov_df = cov_df.merge(df, on=['ExonPos', 'Pos'], how='outer')\n",
    "    cov_df = cov_df.fillna(0).sort_values('ExonPos')\n",
    "    cov_df['Chr'] = chrom\n",
    "    # reorder columns\n",
    "    cols = ['Chr', 'Pos', 'ExonPos'] + list(cov_df.columns)[2:-1]\n",
    "    return cov_df.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [f\"{str(s).zfill(3)}_B\" for s in range(45)]\n",
    "cov_df = combine_coverage(bedCov_path, \"chr7\", sample_list)\n",
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a stacked \"tidy version\" of the coverage df for vizualisation in tidyverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_df(df):\n",
    "    return df.drop(columns=['Chr', 'Pos']).set_index('ExonPos').stack().reset_index().rename(columns={'level_1':'sample', 0:'Coverage'})\n",
    "\n",
    "cov_df.to_csv(f\"{output_path}/PON_coverage.csv\", sep='\\t', index=False)\n",
    "\n",
    "tidy_df(cov_df).to_csv(f\"{output_path}/PON_coverage_tidy.csv\", sep='\\t', index=False)\n",
    "\n",
    "# actually I can tidy the data in R with gather:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize the coverage to coverage 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coverage(cov_df, norm_cov=100):\n",
    "    norm_df = cov_df.set_index(['Chr','Pos','ExonPos'])\n",
    "    norm_df = norm_df / norm_df.mean() * norm_cov\n",
    "    return norm_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = normalize_coverage(cov_df)\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df.to_csv(f\"{output_path}/PON_coverage_norm.csv\", sep='\\t', index=False)\n",
    "tidy_df(norm_df).to_csv(f\"{output_path}/PON_coverage_normtidy.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the mean of all the coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean(norm_df):\n",
    "    norm_df = norm_df.set_index(['Chr', 'Pos', 'ExonPos'])\n",
    "    norm_df['meanCov'] = norm_df.mean(axis=1)\n",
    "    norm_df['medianCov'] = norm_df.median(axis=1)\n",
    "    norm_df['std'] = norm_df.std(axis=1)\n",
    "    return norm_df.reset_index()\n",
    "mean_df = add_mean(norm_df)\n",
    "mean_df.to_csv(f\"{output_path}/PON_coverage_mean.csv\", sep='\\t', index=False)\n",
    "tidy_df(mean_df).to_csv(f\"{output_path}/PON_coverage_mean.tidy.csv\", sep='\\t', index=False)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter the coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df['std'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coverage(df, mincov=20, max_mean_std=20):\n",
    "    filter_df = df.query('meanCov > @mincov and std < @max_mean_std')\n",
    "    return filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = filter_coverage(mean_df, mincov=50, max_mean_std=40)\n",
    "filter_df.to_csv(f\"{output_path}/PON_coverage_filter.csv\", sep='\\t', index=False)\n",
    "tidy_df(filter_df).to_csv(f\"{output_path}/PON_coverage_filter.tidy.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove outliers in order to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, std_factor=2.5):\n",
    "    # cycle through all sample cols and remove outliers\n",
    "    for col in list(df.columns)[3:-3]:\n",
    "        df.loc[np.abs(df['meanCov'] - df[col]) / df['std'] > std_factor, col] = np.nan\n",
    "    return add_mean(df.iloc[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_df = remove_outliers(filter_df, std_factor=2)\n",
    "removed_df.to_csv(f\"{output_path}/PON_coverage_removed.csv\", sep='\\t', index=False)\n",
    "tidy_df(removed_df).to_csv(f\"{output_path}/PON_coverage_removed.tidy.csv\", sep='\\t', index=False)\n",
    "removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_PON_coverage(chrom, sample_list, config={\n",
    "    'sample_PON_path': '.', # the folder with the sample/chrom coverages\n",
    "    'outpath':'.',       # where the coverage files are saved\n",
    "    'normCov':100,       # to what value are coverages normalized#\n",
    "    'minCov': 20,        # only exonPositions with the average coverage above minCov are kept\n",
    "    'max_mean_std': 20,  # only exonPositions with a coverage std below max_mean_std are kept\n",
    "    'std_factor': 3,     # only exonPositions straighing within std_factor * std around meanCoverage are kept\n",
    "}):\n",
    "    \n",
    "    # load all sample coverages for one chromosome\n",
    "    cov_df = combine_coverage(config['sample_PON_path'], chrom, sample_list)\n",
    "    \n",
    "    # normalize and add mean values and std\n",
    "    mean_df = add_mean(normalize_coverage(cov_df, norm_cov=config['normCov']))\n",
    "    \n",
    "    # filter hard regions and outlying data points\n",
    "    filter_df = filter_coverage(mean_df, mincov=config['minCov'], max_mean_std=config['max_mean_std'])\n",
    "    final_df = remove_outliers(filter_df, std_factor=config['std_factor'])\n",
    "    \n",
    "    # output\n",
    "    file_name = f\"{output_path}/PON_coverage.{chrom}.removed.csv\"\n",
    "    print(f\"Saving filtered PON file {file_name} to {output_path}\")\n",
    "    final_df.to_csv(file_name, sep='\\t', index=False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'sample_PON_path': bedCov_path,\n",
    "    'output_path': output_path,\n",
    "    'normCov':100,  \n",
    "    'minCov': 20,   \n",
    "    'max_mean_std': 20,\n",
    "    'std_factor': 2,    \n",
    "} \n",
    "sample_list = [f\"{str(s).zfill(3)}_B\" for s in range(45)]\n",
    "\n",
    "df = make_PON_coverage(\"chr7\", sample_list, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
