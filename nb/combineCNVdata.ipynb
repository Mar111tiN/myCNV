{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining chromosome SNP data per sample into WES SNP data\n",
    "### also add EB data if available to filter out bad SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:09:33.924333Z",
     "start_time": "2020-10-02T16:09:33.920187Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the paths\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "shell_path = \"../shell\"\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:09:34.012107Z",
     "start_time": "2020-10-02T16:09:34.008173Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:18:02.611695Z",
     "start_time": "2020-10-02T16:18:02.519797Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{cnv_path}/01_A.chr3.snpEB', sep='\\t').loc[:,['Chr', 'Start', 'Ref','EBscore', 'PoN-Alt']]\n",
    "test[:13]\n",
    "test = pd.read_csv(f'{cnv_path}/01_A.chr3.snp', sep='\\t')\n",
    "test[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine all snp for a sample into one df with corresponding EBscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:29:05.117448Z",
     "start_time": "2020-10-02T16:29:05.110089Z"
    }
   },
   "outputs": [],
   "source": [
    "# try with pd merge\n",
    "import os\n",
    "chrom_list = [f\"chr{chrom + 1}\" for chrom in range(22)] + ['chrX']\n",
    "\n",
    "\n",
    "def combine_SNPdata(sample, cnv_path):\n",
    "    snp_dfs = []\n",
    "    file_base = os.path.join(snp_path, sample)\n",
    "    for chrom in chrom_list:\n",
    "        # reading SNP\n",
    "        file = f\"{file_base}.{chrom}.snp\"\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        print(f\"Reading SNP VAF from {chrom} of sample {sample} from {file}.\")\n",
    "        snp_df = pd.read_csv(file, sep='\\t')\n",
    "        snp_df[['Alt', 'AltDepth']] = snp_df['Alt'].str.extract(r\"([AGCT])([0-9]+)\")\n",
    "        \n",
    "        #reading snpEB\n",
    "        file = f\"{file_base}.{chrom}.snpEB\"\n",
    "        if not os.path.isfile(file):\n",
    "            continue\n",
    "        print(f\"Reading SNP EBscores from {chrom} of sample {sample} from {file}.\")\n",
    "        snpEB_df = pd.read_csv(file, sep='\\t').loc[:,['Chr', 'Start', 'Ref','Alt', 'EBscore', 'PoN-Alt']]\n",
    "        snp_df = snp_df.merge(snpEB_df, on=['Chr', 'Start', 'Ref', 'Alt'])\n",
    "        \n",
    "        snp_dfs.append(snp_df)\n",
    "    snp_df = pd.concat(snp_dfs)\n",
    "    return snp_df.loc[:, [\"Chr\", \"Start\", \"ExonPos\", \"Ref\", \"Depth\", \"Alt\", \"VAF\", \"EBscore\", \"PoN-Alt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:30:07.677734Z",
     "start_time": "2020-10-02T16:30:05.358029Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df = combine_SNPdata(sample, cnv_path)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge sample coverage with Pon coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:45:06.048591Z",
     "start_time": "2020-10-02T16:45:06.042068Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_Covdata(sample, cnv_data_path):\n",
    "    \n",
    "    cover_dfs = []\n",
    "\n",
    "    for chrom in chrom_list:\n",
    "        # reading sampleCoverage\n",
    "        sample_cov_file = os.path.join(cnv_data_path, f\"cnv/{sample}.{chrom}.cov\")\n",
    "        if not os.path.isfile(sample_cov_file):\n",
    "            continue\n",
    "        print(f\"Reading coverage from {chrom} of sample {sample} from {sample_cov_file}.\")\n",
    "        cov_df = pd.read_csv(sample_cov_file, sep='\\t', compression=\"gzip\")\n",
    "        \n",
    "        \n",
    "        #reading PONcoverage\n",
    "        pon_cov_file = os.path.join(cnv_data_path, f\"chromCov/{chrom}.filtered.csv.gz\")\n",
    "        if not os.path.isfile(pon_cov_file):\n",
    "            continue\n",
    "        print(f\"Reading PON coverage of {chrom} from file {pon_cov_file}.\")\n",
    "        pon_df = pd.read_csv(pon_cov_file, sep='\\t', compression=\"gzip\").loc[:,['Chr', 'Pos', 'ExonPos', 'meanCov', 'medianCov', 'std']]\n",
    "        # column rename\n",
    "        trans_dict = {col:f\"PON{col}\" for col in pon_df.columns[3:]}\n",
    "        pon_df = pon_df.rename(columns=trans_dict)\n",
    "        # merge sample with PON coverage\n",
    "        sample_df = cov_df.merge(pon_df, on=['Chr', 'Pos', 'ExonPos'], how=\"inner\").loc[:,['Chr', 'Pos', 'ExonPos', 'Coverage','PONmeanCov', 'PONmedianCov', 'PONstd']]\n",
    "        \n",
    "        # normalize the coverage\n",
    "        sample_df['Coverage'] = sample_df['Coverage'] / sample_df['Coverage'].mean() * 100\n",
    "        cover_dfs.append(sample_df)   \n",
    "    cover_df = pd.concat(cover_dfs)\n",
    "    cover_df['log2ratio'] = np.log2(covere_df['Coverage'] / cover_df['PONmeanCov'])\n",
    "    cover_df['rr100'] = cover_df['log2ratio'].rolling(100).mean()\n",
    "    cover_df['rr200'] = cover_df['log2ratio'].rolling(200).mean()\n",
    "    cover_df['rr500'] = cover_df['log2ratio'].rolling(500).mean()\n",
    "    \n",
    "    return cover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:45:14.560721Z",
     "start_time": "2020-10-02T16:45:07.214652Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "combine_Covdata(sample, cnvdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df = combine_heteroSNP(\"03_A\")\n",
    "snp_df.to_csv(f\"{output_path}/03_A.snp.csv\", sep='\\t', index=False)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a stacked \"tidy version\" of the coverage df for vizualisation in tidyverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_df(df):\n",
    "    return df.drop(columns=['Chr', 'Pos']).set_index('ExonPos').stack().reset_index().rename(columns={'level_1':'sample', 0:'Coverage'})\n",
    "\n",
    "tidy_df(cov_df).to_csv(f\"{output_path}/PON_coverage_tidy.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize the coverage to coverage 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coverage(cov_df):\n",
    "    norm_df = cov_df.set_index(['Chr','Pos','ExonPos'])\n",
    "    norm_df = norm_df / norm_df.mean() * 100\n",
    "    return norm_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = normalize_coverage(cov_df)\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df(norm_df).to_csv(f\"{output_path}/PON_coverage_normtidy.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the mean of all the coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean(norm_df):\n",
    "    norm_df = norm_df.set_index(['Chr', 'Pos', 'ExonPos'])\n",
    "    norm_df['meanCov'] = norm_df.mean(axis=1)\n",
    "    norm_df['medianCov'] = norm_df.median(axis=1)\n",
    "    norm_df['std'] = norm_df.std(axis=1)\n",
    "    return norm_df.reset_index()\n",
    "mean_df = add_mean(norm_df)\n",
    "tidy_df(mean_df).to_csv(f\"{output_path}/PON_coverage_mean.csv\", sep='\\t', index=False)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter the coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df['std'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coverage(df, mincov, maxstd):\n",
    "    filter_df = df.query('meanCov > @mincov and std < @maxstd')\n",
    "    return filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = filter_coverage(mean_df, mincov=20, maxstd=50)\n",
    "tidy_df(filter_df).to_csv(f\"{output_path}/PON_coverage_filter.csv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
