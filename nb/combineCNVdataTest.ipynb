{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining chromosome SNP data per sample into WES SNP data\n",
    "### also add EB data if available to filter out bad SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:09:33.924333Z",
     "start_time": "2020-10-02T16:09:33.920187Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"/Users/martinscience/mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:09:34.012107Z",
     "start_time": "2020-10-02T16:09:34.008173Z"
    }
   },
   "outputs": [],
   "source": [
    "cnvPON_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) combine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) heteroSNP: combine all snp for a sample into one df with corresponding EBscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:29:05.117448Z",
     "start_time": "2020-10-02T16:29:05.110089Z"
    }
   },
   "outputs": [],
   "source": [
    "# try with pd merge\n",
    "import os\n",
    "chrom_list = [f\"chr{chrom + 1}\" for chrom in range(22)] + ['chrX']\n",
    "\n",
    "\n",
    "def combine_SNPdata(sample, sample_cnv_path=\"\", verbose=False):\n",
    "    snp_dfs = []\n",
    "    file_base = os.path.join(sample_cnv_path, sample)\n",
    "    for chrom in chrom_list:\n",
    "        # reading SNP\n",
    "        file = f\"{file_base}.{chrom}.snp\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP VAF from {chrom} of sample {sample} from {file}.\")\n",
    "        snp_df = pd.read_csv(file, sep='\\t')\n",
    "        snp_df[['Alt', 'AltDepth']] = snp_df['Alt'].str.extract(r\"([AGCT])([0-9]+)\")\n",
    "        \n",
    "        #reading snpEB\n",
    "        file = f\"{file_base}.{chrom}.snpEB\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP EBscores from {chrom} of sample {sample} from {file}.\")\n",
    "        snpEB_df = pd.read_csv(file, sep='\\t').loc[:,['Chr', 'Start', 'Ref','Alt', 'EBscore', 'PoN-Alt']]\n",
    "        snp_df = snp_df.merge(snpEB_df, on=['Chr', 'Start', 'Ref', 'Alt'])\n",
    "        \n",
    "        snp_dfs.append(snp_df)\n",
    "    snp_df = pd.concat(snp_dfs)\n",
    "    return snp_df.loc[:, [\"Chr\", \"Start\", \"ExonPos\", \"Ref\", \"Depth\", \"Alt\", \"VAF\", \"EBscore\", \"PoN-Alt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:30:07.677734Z",
     "start_time": "2020-10-02T16:30:05.358029Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df = combine_SNPdata(sample, sample_cnv_path=cnv_path)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) coverage: merge sample coverage with Pon coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make full ExomCoords\n",
    "+ get the last coords of the chromosome\n",
    "+ make a running sum\n",
    "+ add that to the ExonPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:45:06.048591Z",
     "start_time": "2020-10-02T16:45:06.042068Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_exon_pos(df):\n",
    "    '''\n",
    "    adds the accumulated exonic position (over all chroms)\n",
    "    '''\n",
    "    \n",
    "    # save the output columns\n",
    "    cols = list(df.columns)\n",
    "    df = df.reset_index(drop=True)\n",
    "    # adds the last ExonPos of chrom to start of next chromosome\n",
    "    df.loc[:,'chromStep'] = df.shift(1)['ExonPos'].fillna(0).astype(int)\n",
    "    df.loc[df['Chr'] == df.shift(1)['Chr'],'chromStep'] = 0\n",
    "    df['chromAccum'] = df['chromStep'].cumsum()\n",
    "    df['FullExonPos'] = df['ExonPos'] + df['chromAccum']\n",
    "    cols = cols[:2] + ['FullExonPos'] + cols[2:] + ['chromAccum']\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def combine_Covdata(sample, sample_cnv_path=\"\", PON_cnv_path=\"\", verbose=False):\n",
    "    \n",
    "    cover_dfs = []\n",
    "\n",
    "    for chrom in chrom_list:\n",
    "        # reading sampleCoverage\n",
    "        sample_cov_file = os.path.join(sample_cnv_path, f\"{sample}.{chrom}.cov\")\n",
    "        if not os.path.isfile(sample_cov_file):\n",
    "            print(\"No file\", sample_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading coverage from {chrom} of sample {sample} from {sample_cov_file}.\")\n",
    "        cov_df = pd.read_csv(sample_cov_file, sep='\\t', compression=\"gzip\")\n",
    "        \n",
    "        #reading PONcoverage\n",
    "        pon_cov_file = os.path.join(PON_cnv_path, f\"{chrom}.filtered.csv.gz\")\n",
    "        if not os.path.isfile(pon_cov_file):\n",
    "            print(\"No file\", pon_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading PON coverage of {chrom} from file {pon_cov_file}.\")\n",
    "        pon_df = pd.read_csv(pon_cov_file, sep='\\t', compression=\"gzip\").loc[:,['Chr', 'Pos', 'ExonPos', 'meanCov', 'medianCov', 'std']]\n",
    "        # column rename\n",
    "        trans_dict = {col:f\"PON{col}\" for col in pon_df.columns[3:]}\n",
    "        pon_df = pon_df.rename(columns=trans_dict)\n",
    "        # merge sample with PON coverage\n",
    "        sample_df = cov_df.merge(pon_df, on=['Chr', 'Pos', 'ExonPos'], how=\"inner\").loc[:,['Chr', 'Pos', 'ExonPos', 'Coverage','PONmeanCov', 'PONmedianCov', 'PONstd']]\n",
    "        \n",
    "        # normalize the coverage\n",
    "        sample_df['Coverage'] = sample_df['Coverage'] / sample_df['Coverage'].mean() * 100\n",
    "        cover_dfs.append(sample_df)   \n",
    "    cover_df = pd.concat(cover_dfs)\n",
    "    cover_df['log2ratio'] = np.log2(cover_df['Coverage'] / cover_df['PONmeanCov'])    \n",
    "    return get_full_exon_pos(cover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:45:14.560721Z",
     "start_time": "2020-10-02T16:45:07.214652Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "cov_df = combine_Covdata(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=True)\n",
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the exome coordinates for snp_df from the cov_df\n",
    "+ cov_df is more complete\n",
    "+ needed to have a common coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_exon_pos_from_cov(snp_df, cov_df):\n",
    "    snp_cols = list(snp_df.columns)\n",
    "    snp_df = snp_df.merge(cov_df.loc[:,['Chr', 'chromAccum']].groupby('Chr').first().reset_index(), on='Chr')\n",
    "    snp_df['FullExonPos'] = snp_df['ExonPos'] + snp_df['chromAccum']\n",
    "    cols = snp_cols[:2] + ['FullExonPos'] + snp_cols[2:]\n",
    "    return snp_df[cols], cov_df.drop(columns='chromAccum')\n",
    "\n",
    "snp_df, cov_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the log2ratio at a SNP position by merging snp_df and cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_log2ratio(snp_df, cov_df):\n",
    "    '''\n",
    "    takes the coverage data and approximates the log2ratio for that SNP from adjacent cov data\n",
    "    '''\n",
    "    \n",
    "    # merge snp_df and cov_df and rename required columns\n",
    "    merge_df = snp_df.merge(cov_df, on=[\n",
    "        'Chr',\n",
    "        'FullExonPos'\n",
    "    ], how='outer').sort_values('FullExonPos').reset_index(drop=True).drop(\n",
    "        columns=['Pos'] + list(cov_df.columns[4:-1])\n",
    "    )\n",
    "    \n",
    "    # store the fitting SNPs\n",
    "    merged_df = merge_df.query('EBscore == EBscore and log2ratio == log2ratio').drop(columns='ExonPos_y').rename(columns={'ExonPos_x':'ExonPos'})\n",
    "    \n",
    "    # go on with the SNPs with missing log2ratio\n",
    "    merge_df = merge_df.query('EBscore != EBscore or log2ratio != log2ratio').rename(columns={\n",
    "        'ExonPos_x':'ExonPos', \n",
    "        'ExonPos_y':'ExonPosL', \n",
    "        'log2ratio':'log2ratioL'\n",
    "    })\n",
    "    \n",
    "    merge_dfs = []\n",
    "    snp_cols = list(snp_df.columns) + ['log2ratio']\n",
    "    \n",
    "    for chrom in merge_df['Chr'].unique():\n",
    "        merge = merge_df.query('Chr == @chrom')\n",
    "        merge['ExonPosR'] = merge['ExonPosL'].fillna(method=\"bfill\")\n",
    "        merge['log2ratioR'] = merge['log2ratioL'].fillna(method=\"bfill\")\n",
    "        merge['ExonPosL'] = merge['ExonPosL'].fillna(method=\"ffill\")\n",
    "        merge['log2ratioL'] = merge['log2ratioL'].fillna(method=\"ffill\")\n",
    "        merge['log2ratio'] = merge['log2ratioL'] + (merge['log2ratioR'] - merge['log2ratioL']) / (merge['ExonPosR'] - merge['ExonPosL']) * (merge['ExonPos'] - merge['ExonPosL'])\n",
    "        merge_dfs.append(merge.loc[:, snp_cols])\n",
    "    snp_df = pd.concat(merge_dfs).sort_values('FullExonPos').query('EBscore == EBscore')\n",
    "    snp_df['log2ratio'] = snp_df['log2ratio'].fillna(method='bfill')\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = approx_log2ratio(snp_df, cov_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerVAF(snp_df):\n",
    "    '''\n",
    "    attempting to correct for off-center VAF means\n",
    "    '''\n",
    "    \n",
    "    # get the VAF mean\n",
    "    meanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    # init the new variable\n",
    "    snp_df['centeredVAF'] = 0.5\n",
    "    snp_df.loc[snp_df['VAF'] <= meanVAF, 'centeredVAF'] = snp_df['VAF'] / meanVAF * 0.5\n",
    "    snp_df.loc[snp_df['VAF'] > meanVAF, 'centeredVAF'] = 0.5 + 0.5 * (snp_df['VAF'] - meanVAF) / (1-meanVAF)\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df = centerVAF(snp_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df['centeredVAF'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine SNP data and covData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covNsnp(sample, sample_cnv_path='', PON_cnv_path='', verbose=False):\n",
    "    '''\n",
    "    load the coverage_data for a sample and the heteroSNP data and apply the same fullExonCoords\n",
    "    '''\n",
    "    print(f'Loading coverage data for sample {sample}')\n",
    "    cov_df = combine_Covdata(sample, sample_cnv_path=sample_cnv_path, PON_cnv_path=PON_cnv_path, verbose=verbose)\n",
    "    print(f'Loading SNP data for sample {sample}')\n",
    "    snp_df = combine_SNPdata(sample, sample_cnv_path=sample_cnv_path, verbose=verbose)\n",
    "    # get full exonPos from cov_df and remove the accumPos from cov_df\n",
    "    snp_df, cov_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "    # get lo\n",
    "    snp_df = approx_log2ratio(snp_df, cov_df)\n",
    "    # \n",
    "    snp_df = centerVAF(snp_df)\n",
    "    print(f\"Finished loading sample {sample}\")\n",
    "    return snp_df, cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df, cov_df = get_covNsnp(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
