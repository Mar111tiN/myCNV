{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:39:01.023012Z",
     "start_time": "2020-10-28T10:39:01.008122Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "import os\n",
    "import scipy\n",
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from plot import plot_snp\n",
    "from rollingCNV import one_col_rolling\n",
    "\n",
    "home = '/Users/mahtin'\n",
    "# home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:55:18.699210Z",
     "start_time": "2020-10-28T08:55:18.695175Z"
    }
   },
   "outputs": [],
   "source": [
    "cnvPON_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the coverage and SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:55:21.718470Z",
     "start_time": "2020-10-28T08:55:20.811006Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snpcov_df = pd.read_csv(os.path.join(output_path, f'rollingCNV/{sample}.snpcov.csv'), sep='\\t')\n",
    "rolling_cov_df = pd.read_csv(os.path.join(output_path, f'rollingCNV/{sample}.rollcov.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:55:23.884905Z",
     "start_time": "2020-10-28T08:55:23.870932Z"
    }
   },
   "outputs": [],
   "source": [
    "snpcov_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:57:07.686158Z",
     "start_time": "2020-10-28T08:57:07.653036Z"
    }
   },
   "outputs": [],
   "source": [
    "snpcov_df.query('log2ratiomean != log2ratiomean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:58:00.424815Z",
     "start_time": "2020-10-28T08:58:00.415793Z"
    }
   },
   "outputs": [],
   "source": [
    "rolling_cov_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T08:58:05.825505Z",
     "start_time": "2020-10-28T08:58:05.109185Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_params = dict(\n",
    "    figsize=(50,8),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(-1.5,2.5)\n",
    ")\n",
    "\n",
    "log2mean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='yellow',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "log2diff = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomeanDiff',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='blue',\n",
    "            alpha=.7\n",
    "        ))\n",
    "\n",
    "vaf = dict(\n",
    "        title='VAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='VAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.3,\n",
    "            color='black',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))\n",
    "\n",
    "\n",
    "plots = [\n",
    "    log2mean,\n",
    "    vaf\n",
    "]\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_genomic(snpcov_df, plots=plots, chroms='all', region='', **fig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heteroSNP rolling window\n",
    "+ #### first, the center cluster has to be fitted via clustering to identify the centers for mean correction\n",
    "+ #### look at the distribution of VAF and rolling log2ratio\n",
    "+ #### chrX seems to have different log2ratio (maybe adjusted for XX and XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:08.882231Z",
     "start_time": "2020-10-27T21:21:08.655854Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(snpcov_df['log2ratiomean'], snpcov_df['VAF'], s=.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:09.686129Z",
     "start_time": "2020-10-27T21:21:09.496069Z"
    }
   },
   "outputs": [],
   "source": [
    "merge = snpcov_df.query('Chr != \"chrX\"').query('0.05 < VAF < 0.95 and log2ratiomean == log2ratiomean')\n",
    "plt.scatter(merge['log2ratiomean'], merge['VAF'], s=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### try DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:12:38.246113Z",
     "start_time": "2020-10-27T21:12:33.462464Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# get the matrix\n",
    "X = merge[['log2ratiomean', 'VAF']]\n",
    "rows = X.shape[0]\n",
    "labels = DBSCAN(eps=.2, min_samples=int(rows/3.5)).fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1, cmap='viridis')\n",
    "cluster, counts = np.unique(labels, return_counts=True)\n",
    "len(cluster[cluster != -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### DBSCAN seems to be best fitted for removing the center mass as the spread is hard to guess\n",
    "    * perform a grid search on eps and min_samples to find the maximum center mass with just one cluster\n",
    "    * better!: perform this grid search on multi-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T08:05:27.928849Z",
     "start_time": "2020-10-27T07:57:49.691312Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_count = X.shape[0]\n",
    "max_counts = 0\n",
    "for i in np.linspace(1,6,10):\n",
    "    for ep in np.logspace(-1.5,0,10):\n",
    "        ms = int(sample_count / i)\n",
    "        model = DBSCAN(eps=0.2, min_samples=ms)\n",
    "        labels = model.fit_predict(X)\n",
    "        cluster, counts = np.unique(labels, return_counts=True)\n",
    "        # get the number of clusters \n",
    "        cluster_count = len(cluster[cluster != -1])\n",
    "        # get the size of cluster 0\n",
    "        cluster_size = counts[cluster == 0]\n",
    "        if cluster_count:\n",
    "            if cluster_size > max_counts:\n",
    "                best_model = model\n",
    "        print(f\"ep:{ep}|min_samples:{ms}>> {cluster_count} clusters | cluster0: {cluster_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:12:44.278487Z",
     "start_time": "2020-10-27T21:12:44.268139Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = best_model.fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### GMM clustering runs best for fitting the center mass\n",
    "    * clusters vary depending on init clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:16.981566Z",
     "start_time": "2020-10-27T21:21:15.138529Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "X = merge[['log2ratiomean', 'VAF']]\n",
    "X\n",
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=2, covariance_type='diag', n_init=2)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    axes[i].scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ increasing n_init to 20 does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:22.850811Z",
     "start_time": "2020-10-27T21:21:18.746640Z"
    }
   },
   "outputs": [],
   "source": [
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=2, covariance_type='diag', n_init=20)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    axes[i].scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:59:34.654063Z",
     "start_time": "2020-10-26T17:59:34.649723Z"
    }
   },
   "source": [
    "+ get_centers computes the means from the best fit centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:24.763743Z",
     "start_time": "2020-10-27T21:21:24.757718Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "def get_centers(merge_df, runs=25, VAF_limits=(0.05, 0.95), exclude_X=True):\n",
    "    '''\n",
    "    use GMM to identify the center cluster and get the means from that\n",
    "    because GMM occasionally does not identify the center cluster,\n",
    "    I let the GMM proceed several times and minimize the center cluster\n",
    "    next, the center cluster can be identified as the maximum center\n",
    "    '''\n",
    "    VAFmin, VAFmax = VAF_limits\n",
    "    # fit the centers to the data \n",
    "    if exclude_X:\n",
    "        merge_df = merge_df.query('Chr != \"chrX\"')     \n",
    "    X = merge_df.query('@VAFmin < VAF < @VAFmax and log2ratiomean == log2ratiomean')[['log2ratiomean', 'VAF']]\n",
    "\n",
    "    gmm = GMM(n_components=2, covariance_type='diag', n_init=runs).fit(X)\n",
    "    labels = gmm.predict(X)\n",
    "    # get the size of the \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    maxcount = np.max(counts)\n",
    "    centers = pd.DataFrame(gmm.means_, columns=['log2ratio', 'VAF'])\n",
    "    # get mean_cov and meanVAF from largest cluster\n",
    "    meanCov, meanVAF = centers.loc[np.argmax(counts)]\n",
    "    size = maxcount\n",
    "            \n",
    "    print(f'GMM using {runs} inits: center size {size} meanVAF = {round(meanVAF, 2)} meanCov={round(meanCov, 2)}')\n",
    "    \n",
    "    return meanCov, meanVAF, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:32.660673Z",
     "start_time": "2020-10-27T21:21:31.998487Z"
    }
   },
   "outputs": [],
   "source": [
    "meanCov, meanVAF, centers = get_centers(snpcov_df)\n",
    "meanVAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:23:58.372149Z",
     "start_time": "2020-10-27T21:23:58.366179Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'debug': False, # also export the left and right rolling window values (L/R)\n",
    "    'coverage': {\n",
    "        'filter': dict(\n",
    "            min_cov = 30,\n",
    "            min_PON_cov = 50,\n",
    "            max_PON_std = 100,\n",
    "        ),\n",
    "        'normalize':False,\n",
    "        'center': True,\n",
    "        'expand':0.2, # after interpolation of rolling data from filtered df into full df, interpolate missing data within this fraction of window size, set 0 if no interpolation is wanted\n",
    "        'data': {\n",
    "            'log2ratio': {\n",
    "                'mean':100\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'heteroSNP': {\n",
    "        'filter': dict(\n",
    "            VAF=(0.05,0.95),\n",
    "            minDepth=30,\n",
    "            minEB=0.5\n",
    "        ),\n",
    "        'normalize': True,\n",
    "        'center':False,\n",
    "        'expand': 0.5,\n",
    "        'data': {\n",
    "            'absVAF': {\n",
    "                'sum': 20\n",
    "            },\n",
    "            'VAF': {\n",
    "                'std': 20\n",
    "            },\n",
    "            'deltaVAF': {\n",
    "                'std': 20\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def center_data(snp_df, config):\n",
    "    '''\n",
    "    retrieve the centers for scaling using GMM\n",
    "    '''\n",
    "    \n",
    "    meanCov, meanVAF, _ = get_centers(snp_df, VAF_limits=config['heteroSNP']['filter']['VAF'])\n",
    "    # center coverage \n",
    "    if config['coverage']['center']:\n",
    "        print(\"log2ratio centered around\", meanCov)\n",
    "        snp_df.loc[:, 'log2ratiomean'] = snp_df['log2ratiomean'] - meanCov\n",
    "    if config['heteroSNP']['center']:\n",
    "        print(\"heteroSNP centered around\", meanVAF)\n",
    "        snp_df.loc[:, 'VAF'] = snp_df['VAF'] - meanVAF + 0.5\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:41.946184Z",
     "start_time": "2020-10-27T21:21:41.126805Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df = center_data(snpcov_df, config)\n",
    "snp_df.query('log2ratiomean != log2ratiomean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:46.606403Z",
     "start_time": "2020-10-27T21:21:46.601361Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_SNPdata(snp_df, config):\n",
    "    '''\n",
    "    retrieve a few data columns locally to use rolling windows on\n",
    "    this needs to be done chromosome-wise in order to avoid gap effects\n",
    "    '''\n",
    "    \n",
    "    # get the new features from VAFs\n",
    "    snp_df.loc[:,'absVAF'] = np.abs(snp_df['VAF'] - 0.5) * 2\n",
    "    # get the local VAF difference chrom based\n",
    "    dfs = []\n",
    "    for chrom in snp_df['Chr'].unique():\n",
    "        chrom_df = snp_df.query('Chr == @chrom')\n",
    "        chrom_df.loc[:, 'deltaVAF'] = np.abs(chrom_df['VAF'] - chrom_df.shift(1)['VAF']).fillna(0)\n",
    "        dfs.append(chrom_df)\n",
    "    snp_df = pd.concat(dfs).sort_values('FullExonPos')\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:49.148469Z",
     "start_time": "2020-10-27T21:21:48.806457Z"
    }
   },
   "outputs": [],
   "source": [
    "snp2_df = expand_SNPdata(snp_df, config)\n",
    "snp2_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:21:52.479113Z",
     "start_time": "2020-10-27T21:21:51.775008Z"
    }
   },
   "outputs": [],
   "source": [
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='black',\n",
    "            s=1,\n",
    "            alpha=1\n",
    "        ))\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_genomic(snp_df, plots=[log2mean, absvaf], chroms='all', region='', **fig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:24:04.152092Z",
     "start_time": "2020-10-27T21:24:04.146442Z"
    }
   },
   "outputs": [],
   "source": [
    "def rolling_snp(snp_df, config):\n",
    "    '''\n",
    "    cycle through the chroms and perform rolling window computations of snp data set in config\n",
    "    '''\n",
    "    \n",
    "    # split the params dict for easier access\n",
    "    params = config['heteroSNP']\n",
    "    filter_params = params['filter']\n",
    "    data_params = params['data']\n",
    "    # reduce the snp_df using config limits\n",
    "    VAFmin, VAFmax = filter_params['VAF'] \n",
    "    minDepth = filter_params['minDepth']\n",
    "    minEBscore = filter_params['minEB']\n",
    "    \n",
    "    # cycle through chroms for \n",
    "    chrom_dfs = []\n",
    "    for chrom in snp_df['Chr'].unique():\n",
    "        # restrict to chrom\n",
    "        chrom_df = snp_df.query('Chr == @chrom').sort_values('FullExonPos')        \n",
    "        # filter df\n",
    "        filter_df = snp_df.query('@VAFmin < VAF < @VAFmax and Depth >= @minDepth and EBscore > @minEBscore')\n",
    "        for data_col in data_params.keys():\n",
    "            for agg in data_params[data_col].keys():\n",
    "                window_size = data_params[data_col][agg]\n",
    "                expand_limit = int(params['expand'] * window_size)\n",
    "                # print(f\"Computing rolling window for {agg} of {data_col} with window size {window_size} on {chrom}\")\n",
    "                chrom_df = one_col_rolling(chrom_df, filter_df, data_col, agg, window_size=window_size, expand_limit=expand_limit, normalize=params['normalize'], debug=config['debug'])\n",
    "        chrom_dfs.append(chrom_df)\n",
    "    df = pd.concat(chrom_dfs).sort_values('FullExonPos')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:24:09.489737Z",
     "start_time": "2020-10-27T21:24:06.108826Z"
    }
   },
   "outputs": [],
   "source": [
    "snp3_df = rolling_snp(snp2_df, config)\n",
    "snp3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T08:11:29.950830Z",
     "start_time": "2020-10-14T08:11:29.931804Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(col, agg='mean', modes=['L', 'R', 'Diff', '']):\n",
    "    '''\n",
    "    creates for each col a dict for looped computation\n",
    "    {'L': 'VAVsumL', 'R': 'VAVsumR', 'Diff': 'VAVsumDiff', '': 'VAFsum'}}\n",
    "    '''\n",
    "    cols = {mode: col + agg + mode for mode in modes}\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_rolling_metrix_chrom(df, col='VAF', agg='sum', chrom='', window_size=20):\n",
    "    '''\n",
    "    take a column and produce rolling windows from it for each chromosome\n",
    "    '''\n",
    "    \n",
    "    df = df.query('Chr == @chrom')\n",
    "    cols = get_cols(col, agg)\n",
    "    \n",
    "    # get the right computation\n",
    "    if agg =='std':\n",
    "        df.loc[:, cols['L']] = df.rolling(window_size)[col].std()\n",
    "    if agg == 'sum':\n",
    "        df.loc[:, cols['L']] = df.rolling(window_size)[col].sum()\n",
    "    if agg == 'mean':\n",
    "        df.loc[:, cols['L']] = df.rolling(window_size)[col].mean()\n",
    "\n",
    "    \n",
    "    # get the right window by shifting the left\n",
    "    df.loc[:, cols['R']] = df.shift(-window_size + 1)[cols['L']]\n",
    "    # fillup the margins\n",
    "    df.loc[:, cols['L']] = df[cols['L']].fillna(method='bfill')\n",
    "    df.loc[:, cols['R']] = df[cols['R']].fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_rolling_metrix(df, col='VAF', agg='mean', window_size=20, normalize=True):\n",
    "    '''\n",
    "    wrapper to apply get_rolling_metrix_chrom per chromosome\n",
    "    '''\n",
    "    \n",
    "    chrom_dfs = []\n",
    "    for chrom in df['Chr'].unique():\n",
    "        chrom_df = get_rolling_metrix_chrom(df, col=col, agg=agg, chrom=chrom, window_size=window_size)\n",
    "        chrom_dfs.append(chrom_df)\n",
    "    df = pd.concat(chrom_dfs).sort_values('FullExonPos')\n",
    "    \n",
    "    cols = get_cols(col, agg)\n",
    "    if normalize:\n",
    "    # normalize the data\n",
    "        print('Normalizing data')\n",
    "        _min = df[cols['L']].min()\n",
    "        _max = df[cols['L']].max()\n",
    "        for side in ['L', 'R']:\n",
    "            c = cols[side]\n",
    "            df[c] = (df[c] - _min) / (_max - _min)\n",
    "    # get the Diff\n",
    "    df[cols['Diff']] = ((df[cols['L']] - df[cols['R']]) / 2) + 0.5\n",
    "    df[cols['']] = df[cols['L']] * df[cols['Diff']] + df[cols['R']] * (1 - df[cols['Diff']])\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollingSNP_df = rolling_it(snp_df, config['heteroSNP'])\n",
    "rollingSNP_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df = rolling_it(cov_df, config['coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_data(snp_df, cov_df, config):\n",
    "    '''\n",
    "    add the rolling metrices needed to get local data\n",
    "    '''\n",
    "    \n",
    "    # add extra cols to snp_df\n",
    "    snp_df = expand_SNPdata(snp_df, config['heteroSNP'])\n",
    "    \n",
    "    # get the rolling metrices for snp_df\n",
    "    snp_df = rolling_it(snp_df, config['heteroSNP'])\n",
    "    # get the rolling metrices for cov_df\n",
    "    cov_df = rolling_it(cov_df, config['coverage'])\n",
    "    \n",
    "    return snp_df, cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df, cov_df = add_rolling_data(snp_df, cov_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df.to_csv(os.path.join(output_path, 'heteroSNP/01_A.snp'), sep='\\t', index=False)\n",
    "cov_df.to_csv(os.path.join(output_path, 'covDif/01_A.cov'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerVAF(snp_df):\n",
    "    '''\n",
    "    attempting to correct for off-center VAF means\n",
    "    '''\n",
    "\n",
    "    # get the VAF mean\n",
    "    meanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    # store the original VAF in orgVAF\n",
    "    snp_df['orgVAF'] = snp_df['VAF']\n",
    "    snp_df.loc[snp_df['VAF'] <= meanVAF,\n",
    "               'VAF'] = snp_df['VAF'] / meanVAF * 0.5\n",
    "    snp_df.loc[snp_df['VAF'] > meanVAF, 'VAF'] = 0.5 + \\\n",
    "        0.5 * (snp_df['VAF'] - meanVAF) / (1-meanVAF)\n",
    "    newMeanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    return snp_df, meanVAF, newMeanVAF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
