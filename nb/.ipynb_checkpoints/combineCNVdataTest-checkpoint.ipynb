{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining chromosome SNP data per sample into WES SNP data\n",
    "### also add EB data if available to filter out bad SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T03:59:00.885927Z",
     "start_time": "2020-10-09T03:59:00.880990Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"/Users/martinscience/mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T03:59:02.470404Z",
     "start_time": "2020-10-09T03:59:02.466546Z"
    }
   },
   "outputs": [],
   "source": [
    "cnvPON_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) combine the data from individual chroms into exom df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) coverage: merge sample coverage with Pon coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make full ExomCoords\n",
    "+ get the last coords of the chromosome\n",
    "+ make a running sum\n",
    "+ add that to the ExonPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:21:56.550172Z",
     "start_time": "2020-10-09T04:21:56.546195Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_exon_pos(df):\n",
    "    '''\n",
    "    adds the accumulated exonic position (over all chroms)\n",
    "    '''\n",
    "    \n",
    "    # save the output columns\n",
    "    cols = list(df.columns)\n",
    "    df = df.reset_index(drop=True)\n",
    "    # adds the last ExonPos of chrom to start of next chromosome\n",
    "    df.loc[:,'chromStep'] = df.shift(1)['ExonPos'].fillna(0).astype(int)\n",
    "    df.loc[df['Chr'] == df.shift(1)['Chr'],'chromStep'] = 0\n",
    "    df['chromAccum'] = df['chromStep'].cumsum()\n",
    "    df['FullExonPos'] = df['ExonPos'] + df['chromAccum']\n",
    "    cols = cols[:2] + ['FullExonPos'] + cols[2:] + ['chromAccum']\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:25:19.365998Z",
     "start_time": "2020-10-09T04:25:19.357320Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_Covdata(sample, sample_cnv_path=\"\", PON_cnv_path=\"\", verbose=False, filtered=True):\n",
    "    \n",
    "    cover_dfs = []\n",
    "\n",
    "    for chrom in chrom_list:\n",
    "        # reading sampleCoverage\n",
    "        sample_cov_file = os.path.join(sample_cnv_path, f\"{sample}.{chrom}.cov\")\n",
    "        if not os.path.isfile(sample_cov_file):\n",
    "            print(\"No file\", sample_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading coverage from {chrom} of sample {sample} from {sample_cov_file}.\")\n",
    "        cov_df = pd.read_csv(sample_cov_file, sep='\\t', compression=\"gzip\")\n",
    "        \n",
    "        #reading PONcoverage\n",
    "        full_or_filtered = \"filtered\" if filtered else \"full\"\n",
    "        pon_cov_file = os.path.join(PON_cnv_path, f\"{chrom}.{full_or_filtered}.csv.gz\")\n",
    "        if not os.path.isfile(pon_cov_file):\n",
    "            print(\"No file\", pon_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading PON coverage of {chrom} from file {pon_cov_file}.\")\n",
    "        pon_df = pd.read_csv(pon_cov_file, sep='\\t', compression=\"gzip\").loc[:,['Chr', 'Pos', 'ExonPos', 'meanCov', 'medianCov', 'std']]\n",
    "        # column rename\n",
    "        trans_dict = {col:f\"PON{col}\" for col in pon_df.columns[3:]}\n",
    "        pon_df = pon_df.rename(columns=trans_dict)\n",
    "        # merge sample with PON coverage\n",
    "        sample_df = cov_df.merge(pon_df, on=['Chr', 'Pos', 'ExonPos'], how=\"inner\").loc[:,['Chr', 'Pos', 'ExonPos', 'Coverage','PONmeanCov', 'PONmedianCov', 'PONstd']]\n",
    "        \n",
    "        # normalize the coverage\n",
    "        sample_df['Coverage'] = sample_df['Coverage'] / sample_df['Coverage'].mean() * 100\n",
    "        cover_dfs.append(sample_df)   \n",
    "    cover_df = pd.concat(cover_dfs)\n",
    "    cover_df['log2ratio'] = np.log2(cover_df['Coverage'] / cover_df['PONmeanCov'])    \n",
    "    return get_full_exon_pos(cover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:25:39.843752Z",
     "start_time": "2020-10-09T04:25:20.131177Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "cov_df = combine_Covdata(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=True, filtered=False)\n",
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) heteroSNP: combine all snp for a sample into one df with corresponding EBscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:12:44.753500Z",
     "start_time": "2020-10-09T04:12:44.745574Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "chrom_list = [f\"chr{chrom + 1}\" for chrom in range(22)] + ['chrX']\n",
    "\n",
    "\n",
    "def combine_SNPdata(sample, sample_cnv_path=\"\", verbose=False):\n",
    "    snp_dfs = []\n",
    "    file_base = os.path.join(sample_cnv_path, sample)\n",
    "    for chrom in chrom_list:\n",
    "        # reading SNP\n",
    "        file = f\"{file_base}.{chrom}.snp\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP VAF from {chrom} of sample {sample} from {file}.\")\n",
    "        snp_df = pd.read_csv(file, sep='\\t')\n",
    "        snp_df[['Alt', 'AltDepth']] = snp_df['Alt'].str.extract(r\"([AGCT])([0-9]+)\")\n",
    "        \n",
    "        #reading snpEB\n",
    "        file = f\"{file_base}.{chrom}.snpEB\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP EBscores from {chrom} of sample {sample} from {file}.\")\n",
    "        snpEB_df = pd.read_csv(file, sep='\\t').loc[:,['Chr', 'Start', 'Ref','Alt', 'EBscore', 'PoN-Alt']]\n",
    "        snp_df = snp_df.merge(snpEB_df, on=['Chr', 'Start', 'Ref', 'Alt'])\n",
    "        \n",
    "        snp_dfs.append(snp_df)\n",
    "    snp_df = pd.concat(snp_dfs).reset_index(drop=True)\n",
    "    return snp_df.loc[:, [\"Chr\", \"Start\", \"ExonPos\", \"Ref\", \"Depth\", \"Alt\", \"VAF\", \"EBscore\", \"PoN-Alt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:12:47.768318Z",
     "start_time": "2020-10-09T04:12:45.241380Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df = combine_SNPdata(sample, sample_cnv_path=cnv_path)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:12:47.825117Z",
     "start_time": "2020-10-09T04:12:47.821335Z"
    }
   },
   "outputs": [],
   "source": [
    "def centerVAF(snp_df):\n",
    "    '''\n",
    "    attempting to correct for off-center VAF means\n",
    "    '''\n",
    "\n",
    "    # get the VAF mean\n",
    "    meanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    # store the original VAF in orgVAF\n",
    "    snp_df['orgVAF'] = snp_df['VAF']\n",
    "    snp_df.loc[snp_df['VAF'] <= meanVAF,\n",
    "               'VAF'] = snp_df['VAF'] / meanVAF * 0.5\n",
    "    snp_df.loc[snp_df['VAF'] > meanVAF, 'VAF'] = 0.5 + \\\n",
    "        0.5 * (snp_df['VAF'] - meanVAF) / (1-meanVAF)\n",
    "    newMeanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    return snp_df, meanVAF, newMeanVAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:01.314824Z",
     "start_time": "2020-10-09T04:13:01.263666Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df = centerVAF(snp_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:08.981802Z",
     "start_time": "2020-10-09T04:13:08.967647Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:10.487362Z",
     "start_time": "2020-10-09T04:13:10.474248Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df.query('0.05 < VAF < 0.95')['centeredVAF'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the exome coordinates for snp_df from the cov_df\n",
    "+ cov_df is more complete\n",
    "+ needed to have a common coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:16.393614Z",
     "start_time": "2020-10-09T04:13:16.131543Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_exon_pos_from_cov(snp_df, cov_df):\n",
    "    snp_cols = list(snp_df.columns)\n",
    "    snp_df = snp_df.merge(cov_df.loc[:,['Chr', 'chromAccum']].groupby('Chr').first().reset_index(), on='Chr')\n",
    "    snp_df['FullExonPos'] = snp_df['ExonPos'] + snp_df['chromAccum']\n",
    "    cols = snp_cols[:2] + ['FullExonPos'] + snp_cols[2:]\n",
    "    return snp_df[cols], cov_df.drop(columns='chromAccum')\n",
    "\n",
    "snp_df, cov_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:28.691761Z",
     "start_time": "2020-10-09T04:13:28.676774Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine SNP data and covData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covNsnp(sample, sample_cnv_path='', PON_cnv_path='', verbose=False):\n",
    "    '''\n",
    "    load the coverage_data for a sample and the heteroSNP data and apply the same fullExonCoords\n",
    "    '''\n",
    "    print(f'Loading coverage data for sample {sample}')\n",
    "    cov_df = combine_Covdata(sample, sample_cnv_path=sample_cnv_path, PON_cnv_path=PON_cnv_path, verbose=verbose)\n",
    "    print(f'Loading SNP data for sample {sample}')\n",
    "    snp_df = combine_SNPdata(sample, sample_cnv_path=sample_cnv_path, verbose=verbose)\n",
    "    # get full exonPos from cov_df and remove the accumPos from cov_df\n",
    "    snp_df, cov_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "    # \n",
    "    snp_df, _, _ = centerVAF(snp_df)\n",
    "    print(f\"Finished loading sample {sample}\")\n",
    "    return snp_df, cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df, cov_df = get_covNsnp(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
