{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SNP and COV data into one df for clustering\n",
    "+ all local data points must have been converted to reliable rolling values and correct filtering has been applied:\n",
    "    * minDepth + EBscore for heteroSNPs\n",
    "    * minCoverage and maxStd for cov data\n",
    "\n",
    "\n",
    "\n",
    "+ use a constant binning for sampling the average data\n",
    "    * all local values can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.max_columns = 37\n",
    "pd.options.display.max_rows = 100\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:09:33.924333Z",
     "start_time": "2020-10-02T16:09:33.920187Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"/Users/martinscience/mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load snp_df and cov_df with rolling metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df = pd.read_csv(os.path.join(output_path, 'heteroSNP/01_A.snp'), sep='\\t')\n",
    "cov_df = pd.read_csv(os.path.join(output_path, 'covDif/01_A.cov'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from merge_cnv2snp import mergeSNP2Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'heteroSNP': {\n",
    "        'VAFlimits':[0.05,0.95],\n",
    "        'normalize': True,\n",
    "        'windows': {\n",
    "            'absVAF': {\n",
    "                'sum': 20\n",
    "            },\n",
    "            'VAF': {\n",
    "                'std': 20\n",
    "            },\n",
    "            'deltaVAF': {\n",
    "                'std': 20\n",
    "            }\n",
    "        },\n",
    "        'minEBscore':0.5,\n",
    "        'minDepth': 30,\n",
    "    },\n",
    "    'coverage': {\n",
    "        'VAFlimits':[0.05,0.95],\n",
    "        'normalize':False,\n",
    "        'windows': {\n",
    "            'log2ratio': {\n",
    "                'mean':500\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "merge_df = mergeSNP2Cov(snp_df, cov_df, config)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv(os.path.join(output_path, 'cluster/01_A_merged.cnv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk me through it.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge both dfs per chrom and combine the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the required snp_df columns for merge\n",
    "snp_cols = ['Chr', 'Start', 'FullExonPos', 'ExonPos', 'VAF']\n",
    "for metrix in ['absVAFsum', 'deltaVAFstd', 'VAFstd']:\n",
    "    snp_cols += [col for col in snp_df.columns if col.startswith(metrix)]\n",
    "\n",
    "snp_chrom_df = snp_df.loc[:,snp_cols]\n",
    "snp_chrom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the required cov_df columns for merge\n",
    "cov_chrom_df = cov_df.loc[:, ['Chr', 'Pos', 'FullExonPos', 'ExonPos', 'log2ratiomeanDiff', 'log2ratiomean']]\n",
    "\n",
    "merge_df = snp_chrom_df.merge(cov_chrom_df, on=['Chr', 'FullExonPos'], how='outer').sort_values('FullExonPos').rename(columns={\n",
    "    'ExonPos_x': 'PosSNP',\n",
    "    'ExonPos_y': 'PosCov'\n",
    "})\n",
    "\n",
    "# merge chromosomal start coords\n",
    "merge_df.loc[merge_df['Start'] != merge_df['Start'], 'Start'] = merge_df['Pos']\n",
    "merge_df['Start'] = merge_df['Start'].astype(int)\n",
    "merge_df = merge_df.drop(columns='Pos').reset_index(drop=True).sort_values('FullExonPos')\n",
    "merge_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv(os.path.join(output_path, 'cluster/01_A_staggered.cnv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the ones that are already merged\n",
    "\n",
    "# store the fitting values as merged_df\n",
    "merged_df = merge_df.query('VAF == VAF and log2ratiomean == log2ratiomean')\n",
    "\n",
    "# go on with the SNPs with non-fitting data\n",
    "merge_df = merge_df.query('VAF != VAF or log2ratiomean != log2ratiomean')\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### go on with chrom-separate merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = 'chr5'\n",
    "merge = merge_df.query('Chr == @chrom')\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on VAFstd for simplicity\n",
    "\n",
    "def approximate_data(merge, col='VAFstd', pos_col='PosSNP', trans_pos_col='PosCov'):\n",
    "    '''\n",
    "    takes the data values from col at positions in pos_col \n",
    "    and linearly approximates data values into merged rows at positions in trans_pos_col\n",
    "    '''\n",
    "    \n",
    "    cols = list(merge.columns)\n",
    "    # find the adjacent positions for missing rows and store in PosL and PosR\n",
    "    merge.loc[:,'PosL'] = merge[pos_col].fillna(method=\"ffill\")\n",
    "    merge.loc[:,'PosR'] = merge[pos_col].fillna(method=\"bfill\")\n",
    "    # find the adjacent data values for missing rows and store in L and R\n",
    "    merge.loc[:,'L'] = merge[col].fillna(method=\"ffill\")\n",
    "    merge.loc[:,'R'] = merge[col].fillna(method=\"bfill\")\n",
    "    # approximate the missing values\n",
    "    merge.loc[merge[col] != merge[col], col] = merge['L'] + (merge['R'] - merge['L']) / (\n",
    "            merge['PosR'] - merge['PosL']) * (merge[trans_pos_col] - merge['PosL'])\n",
    "    # close the gaps\n",
    "    merge.loc[:,col] = merge[col].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # return the only the original columns with filled in values\n",
    "    return merge.loc[:,cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = approximate_data(merge, col='VAFstd', pos_col='PosSNP', trans_pos_col='PosCov')\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approx_col_list(config):\n",
    "    '''\n",
    "    generates a list of dictionaries with data columns to be approximated\n",
    "    from the config to be consumed by the approximator\n",
    "    '''\n",
    "    \n",
    "    # approx_cols is the list of \n",
    "    approx_cols = []\n",
    "    snp_conf = config['heteroSNP']['windows']\n",
    "\n",
    "     \n",
    "    for col in snp_conf.keys():\n",
    "        for mode in snp_conf[col].keys():\n",
    "            approx_cols.append({\n",
    "                'col':f\"{col}{mode}\",\n",
    "                'pos_col':'PosSNP',\n",
    "                'trans_pos_col': 'PosCov'\n",
    "            })\n",
    "    cov_conf = config['coverage']['windows']\n",
    "    for col in cov_conf.keys():\n",
    "        for mode in cov_conf[col].keys():\n",
    "            approx_cols.append({\n",
    "                'col':f\"{col}{mode}\",\n",
    "                'pos_col':'PosCov',\n",
    "                'trans_pos_col': 'PosSNP'\n",
    "            })\n",
    "    return approx_cols\n",
    "\n",
    "get_approx_col_list(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the approximation for all the columns defined in the config\n",
    "\n",
    "for data in get_approx_col_list(config):\n",
    "    print(data['col'])\n",
    "    merge = approximate_data(merge, col=data['col'], pos_col=data['pos_col'], trans_pos_col=data['trans_pos_col'])\n",
    "    merge = approximate_data(merge, col=data['col']+\"Diff\", pos_col=data['pos_col'], trans_pos_col=data['trans_pos_col'])\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeSNP2Cov(snp_df, cov_df, config):\n",
    "    '''\n",
    "    for clustering, all data points from SNP\n",
    "    '''\n",
    "    # get the required snp_df columns for merge\n",
    "    snp_cols = ['Chr', 'Start', 'FullExonPos', 'ExonPos', 'VAF']\n",
    "    for metrix in ['absVAFsum', 'deltaVAFstd', 'VAFstd']:\n",
    "        snp_cols += [col for col in snp_df.columns if col.startswith(metrix)]\n",
    "\n",
    "    snp_chrom_df = snp_df.loc[:,snp_cols]\n",
    "\n",
    "    # get the required cov_df columns for merge\n",
    "    cov_chrom_df = cov_df.loc[:, ['Chr', 'Pos', 'FullExonPos', 'ExonPos', 'log2ratiomeanDiff', 'log2ratiomean']]\n",
    "    \n",
    "    # do the merge and rename the respective ExonPos\n",
    "    merge_df = snp_chrom_df.merge(cov_chrom_df, on=['Chr', 'FullExonPos'], how='outer').sort_values('FullExonPos').rename(columns={\n",
    "        'ExonPos_x': 'PosSNP',\n",
    "        'ExonPos_y': 'PosCov'\n",
    "    })\n",
    "\n",
    "    # merge chromosomal start coords\n",
    "    merge_df.loc[merge_df['Start'] != merge_df['Start'], 'Start'] = merge_df['Pos']\n",
    "    merge_df.loc[:,'Start'] = merge_df['Start'].astype(int)\n",
    "    merge_df = merge_df.drop(columns='Pos').reset_index(drop=True).sort_values('FullExonPos')\n",
    "    \n",
    "    # store the fitting values as merged_df\n",
    "    merged_df = merge_df.query('VAF == VAF and log2ratiomean == log2ratiomean')\n",
    "\n",
    "    # go on with the SNPs with non-fitting data\n",
    "    merge_df = merge_df.query('VAF != VAF or log2ratiomean != log2ratiomean')\n",
    "    \n",
    "    # get the data columns for the approximator\n",
    "    data_col_list = get_approx_col_list(config)\n",
    "    \n",
    "    # go through the chromosomes and do the approximation\n",
    "    merge_dfs = []\n",
    "    for chrom in merge_df['Chr'].unique():\n",
    "        chrom_merge_df = merge_df.query('Chr == @chrom')\n",
    "        for data in data_col_list:\n",
    "            chrom_merge_df = approximate_data(chrom_merge_df, col=data['col'], pos_col=data['pos_col'], trans_pos_col=data['trans_pos_col'])\n",
    "            chrom_merge_df = approximate_data(chrom_merge_df, col=data['col']+\"Diff\", pos_col=data['pos_col'], trans_pos_col=data['trans_pos_col'])\n",
    "        merge_dfs.append(chrom_merge_df)\n",
    "    # concat the chroms and add the already merged df\n",
    "    merge_df = pd.concat(merge_dfs + [merged_df]).sort_values('FullExonPos').rename(columns={'PosSNP':'ExonPos'})\n",
    "    # transfer the missing positions from \n",
    "    merge_df.loc[:, 'ExonPos'] = merge_df['ExonPos'].fillna(merge_df['PosCov'])\n",
    "    return merge_df.drop(columns='PosCov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = mergeSNP2Cov(snp_df, cov_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.sort_values('FullExonPos').query('VAF != VAF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
