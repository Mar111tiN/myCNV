{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining chromosome SNP data per sample into WES SNP data\n",
    "### also add EB data if available to filter out bad SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:15:07.649399Z",
     "start_time": "2020-10-09T09:15:07.644116Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"/Users/martinscience/mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:15:08.316076Z",
     "start_time": "2020-10-09T09:15:08.308643Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from combineCNVdata import get_covNsnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:17:10.265955Z",
     "start_time": "2020-10-09T09:16:51.723449Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df, cov_df = get_covNsnp(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=False, centerSNP=True)\n",
    "snp_df.to_csv(os.path.join(output_path, 'heteroSNP/01_A.snp'), sep='\\t', index=False)\n",
    "cov_df.to_csv(os.path.join(output_path, 'covDif/01_A.cov'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:15:24.036484Z",
     "start_time": "2020-10-09T09:15:24.020952Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:15:27.736084Z",
     "start_time": "2020-10-09T09:15:27.723176Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_df.query('Chr == \"chrX\"').sort_values(['Chr', 'FullExonPos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) combine the data from individual chroms into exom df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) coverage: merge sample coverage with Pon coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make full ExomCoords\n",
    "+ get the last coords of the chromosome\n",
    "+ make a running sum\n",
    "+ add that to the ExonPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:06:25.624366Z",
     "start_time": "2020-10-09T09:06:25.503588Z"
    }
   },
   "outputs": [],
   "source": [
    "chrom = 'chr2'\n",
    "sample = \"01_A\"\n",
    "pon_cov = pd.read_csv(os.path.join(cnvPON_path, f\"{chrom}.filtered.csv.gz\"), sep='\\t', compression=\"gzip\")\n",
    "pon_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:15:16.279118Z",
     "start_time": "2020-10-09T08:15:16.094623Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_cov = pd.read_csv(os.path.join(cnv_path, f\"{sample}.{chrom}.cov\"), sep='\\t', compression=\"gzip\")\n",
    "sample_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:36:35.181313Z",
     "start_time": "2020-10-09T08:36:35.172923Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_Covdata(sample, sample_cnv_path=\"\", PON_cnv_path=\"\", verbose=False, filtered=True):\n",
    "    \n",
    "    cover_dfs = []\n",
    "    chrom_list = [f\"chr{chrom + 1}\" for chrom in range(22)] + ['chrX']\n",
    "    for chrom in chrom_list:\n",
    "        # reading sampleCoverage\n",
    "        sample_cov_file = os.path.join(sample_cnv_path, f\"{sample}.{chrom}.cov\")\n",
    "        if not os.path.isfile(sample_cov_file):\n",
    "            print(\"No file\", sample_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading coverage from {chrom} of sample {sample} from {sample_cov_file}.\")\n",
    "        cov_df = pd.read_csv(sample_cov_file, sep='\\t', compression=\"gzip\")\n",
    "        \n",
    "        #reading PONcoverage\n",
    "        full_or_filtered = \"filtered\" if filtered else \"full\"\n",
    "        pon_cov_file = os.path.join(PON_cnv_path, f\"{chrom}.{full_or_filtered}.csv.gz\")\n",
    "        if not os.path.isfile(pon_cov_file):\n",
    "            print(\"No file\", pon_cov_file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading PON coverage of {chrom} from file {pon_cov_file}.\")\n",
    "        pon_df = pd.read_csv(pon_cov_file, sep='\\t', compression=\"gzip\").loc[:,['Chr', 'Pos', 'FullExonPos', 'ExonPos', 'meanCov', 'medianCov', 'std']]\n",
    "        # column rename\n",
    "        trans_dict = {col:f\"PON{col}\" for col in pon_df.columns[4:]}\n",
    "        pon_df = pon_df.rename(columns=trans_dict)\n",
    "        # merge sample with PON coverage\n",
    "        sample_df = cov_df.merge(pon_df, on=['Chr', 'Pos', 'ExonPos'], how=\"outer\").loc[:,['Chr', 'Pos', 'FullExonPos', 'ExonPos', 'Coverage','PONmeanCov', 'PONmedianCov', 'PONstd']]\n",
    "        \n",
    "        ##### here recover missing FullExonPos from margin\n",
    "        # get \n",
    "        exon_start, full_start = sample_df.iloc[0][['ExonPos', 'FullExonPos']]\n",
    "        offset = full_start - exon_start\n",
    "        sample_df.loc[sample_df['FullExonPos'] != sample_df['FullExonPos'], 'FullExonPos'] = sample_df['ExonPos'] + offset\n",
    "        \n",
    "        # normalize the coverage\n",
    "        sample_df['Coverage'] = (sample_df['Coverage'] / sample_df['Coverage'].mean() * 100).fillna(0)\n",
    "        cover_dfs.append(sample_df)   \n",
    "    cover_df = pd.concat(cover_dfs)\n",
    "    # loggable are the coverages, where log2ratio can be computed\n",
    "    loggable = (cover_df['PONmeanCov'] * cover_df['Coverage'] != 0)\n",
    "    cover_df.loc[loggable, 'log2ratio'] = np.log2(cover_df.loc[loggable, 'Coverage'] / cover_df.loc[loggable, 'PONmeanCov'])\n",
    "    # mark regions without PON coverage as 0\n",
    "    cover_df.loc[~loggable, 'log2ratio'] = np.nan\n",
    "    return cover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:36:41.822701Z",
     "start_time": "2020-10-09T08:36:38.909445Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "cov_df = combine_Covdata(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, filtered=True)\n",
    "cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = cov_df.iloc[0][['Pos', 'FullExonPos']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) heteroSNP: combine all snp for a sample into one df with corresponding EBscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:27:57.900732Z",
     "start_time": "2020-10-09T08:27:57.892854Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "chrom_list = [f\"chr{chrom + 1}\" for chrom in range(22)] + ['chrX']\n",
    "\n",
    "\n",
    "def combine_SNPdata(sample, sample_cnv_path=\"\", verbose=False):\n",
    "    snp_dfs = []\n",
    "    file_base = os.path.join(sample_cnv_path, sample)\n",
    "    for chrom in chrom_list:\n",
    "        # reading SNP\n",
    "        file = f\"{file_base}.{chrom}.snp\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP VAF from {chrom} of sample {sample} from {file}.\")\n",
    "        snp_df = pd.read_csv(file, sep='\\t')\n",
    "        snp_df[['Alt', 'AltDepth']] = snp_df['Alt'].str.extract(r\"([AGCT])([0-9]+)\")\n",
    "        \n",
    "        #reading snpEB\n",
    "        file = f\"{file_base}.{chrom}.snpEB\"\n",
    "        if not os.path.isfile(file):\n",
    "            print('No file', file)\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"Reading SNP EBscores from {chrom} of sample {sample} from {file}.\")\n",
    "        snpEB_df = pd.read_csv(file, sep='\\t').loc[:,['Chr', 'Start', 'Ref','Alt', 'EBscore', 'PoN-Alt']]\n",
    "        snp_df = snp_df.merge(snpEB_df, on=['Chr', 'Start', 'Ref', 'Alt'])\n",
    "        \n",
    "        snp_dfs.append(snp_df)\n",
    "    snp_df = pd.concat(snp_dfs).reset_index(drop=True)\n",
    "    return snp_df.loc[:, [\"Chr\", \"Start\", \"ExonPos\", \"Ref\", \"Depth\", \"Alt\", \"VAF\", \"EBscore\", \"PoN-Alt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:47.061212Z",
     "start_time": "2020-10-09T09:03:44.518800Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df = combine_SNPdata(sample, sample_cnv_path=cnv_path)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:50.191342Z",
     "start_time": "2020-10-09T09:03:50.186693Z"
    }
   },
   "outputs": [],
   "source": [
    "def centerVAF(snp_df):\n",
    "    '''\n",
    "    attempting to correct for off-center VAF means\n",
    "    '''\n",
    "\n",
    "    # get the VAF mean\n",
    "    meanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    # store the original VAF in orgVAF\n",
    "    snp_df['orgVAF'] = snp_df['VAF']\n",
    "    snp_df.loc[snp_df['VAF'] <= meanVAF,\n",
    "               'VAF'] = snp_df['VAF'] / meanVAF * 0.5\n",
    "    snp_df.loc[snp_df['VAF'] > meanVAF, 'VAF'] = 0.5 + \\\n",
    "        0.5 * (snp_df['VAF'] - meanVAF) / (1-meanVAF)\n",
    "    newMeanVAF = snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()\n",
    "    return snp_df, meanVAF, newMeanVAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:50.580060Z",
     "start_time": "2020-10-09T09:03:50.503202Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df, _, _ = centerVAF(snp_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:50.825879Z",
     "start_time": "2020-10-09T09:03:50.813819Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df.query('0.05 < VAF < 0.95')['VAF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:51.242163Z",
     "start_time": "2020-10-09T09:03:51.229926Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df.query('0.05 < VAF < 0.95')['orgVAF'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the exome coordinates for snp_df from the cov_df\n",
    "+ cov_df is more complete\n",
    "+ needed to have a common coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:51.956329Z",
     "start_time": "2020-10-09T09:03:51.942347Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:03:52.414429Z",
     "start_time": "2020-10-09T09:03:52.402176Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:04:16.091232Z",
     "start_time": "2020-10-09T09:04:13.723726Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_exon_pos_from_cov(snp_df, cov_df):\n",
    "    \n",
    "    snp_cols = list(snp_df.columns)\n",
    "    snp_dfs = []\n",
    "    for chrom in snp_df['Chr'].unique():\n",
    "        merge = snp_df.query('Chr == @chrom').merge(cov_df.query('Chr == @chrom').loc[:,['Chr','Pos', 'FullExonPos','ExonPos']], how='outer').sort_values('ExonPos')\n",
    "        merge['PosL'] = merge['Pos'].fillna(method=\"ffill\")\n",
    "        merge['FullL'] = merge['FullExonPos'].fillna(method=\"ffill\")\n",
    "        merge.loc[merge['FullExonPos'] != merge['FullExonPos'], 'FullExonPos'] = merge['FullL'] + merge['Start'] - merge['PosL']\n",
    "        # fill the margins\n",
    "        merge.loc[:,'FullExonPos'] = merge['FullExonPos'].fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "        # reduce the columns and only snp_data rows\n",
    "        cols = snp_cols[:2] + ['FullExonPos'] + snp_cols[2:]\n",
    "        snp_merge = merge[cols].query(\"VAF == VAF\")\n",
    "        for col in ['Start', 'FullExonPos', 'Depth']:\n",
    "            snp_merge.loc[:, col] = snp_merge[col].astype(int)\n",
    "        snp_dfs.append(snp_merge)\n",
    "    snp_df = pd.concat(snp_dfs).reset_index(drop=True).sort_values('FullExonPos').rename(columns={'Start':'Pos'})\n",
    "\n",
    "    return snp_df\n",
    "\n",
    "snp_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T04:13:28.691761Z",
     "start_time": "2020-10-09T04:13:28.676774Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine SNP data and covData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:04:45.659977Z",
     "start_time": "2020-10-09T09:04:45.655999Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_covNsnp(sample, sample_cnv_path='', PON_cnv_path='', verbose=False):\n",
    "    '''\n",
    "    load the coverage_data for a sample and the heteroSNP data and apply the same fullExonCoords\n",
    "    '''\n",
    "    print(f'Loading coverage data for sample {sample}')\n",
    "    cov_df = combine_Covdata(sample, sample_cnv_path=sample_cnv_path, PON_cnv_path=PON_cnv_path, verbose=verbose)\n",
    "    print(f'Loading SNP data for sample {sample}')\n",
    "    snp_df = combine_SNPdata(sample, sample_cnv_path=sample_cnv_path, verbose=verbose)\n",
    "    # get full exonPos from cov_df and remove the accumPos from cov_df\n",
    "    snp_df = get_full_exon_pos_from_cov(snp_df, cov_df)\n",
    "    # \n",
    "    snp_df, _, _ = centerVAF(snp_df)\n",
    "    print(f\"Finished loading sample {sample}\")\n",
    "    return snp_df, cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:04:55.890203Z",
     "start_time": "2020-10-09T09:04:48.100225Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df, cov_df = get_covNsnp(sample, sample_cnv_path=cnv_path, PON_cnv_path=cnvPON_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:05:14.810770Z",
     "start_time": "2020-10-09T09:05:14.796647Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T09:05:15.940324Z",
     "start_time": "2020-10-09T09:05:15.928765Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
