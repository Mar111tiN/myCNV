{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the code\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "sys.path.append('../code')\n",
    "\n",
    "# import package functions\n",
    "from codeCNV.plot import plot_genomic, plot_snp2, plot_snp, plot_2d, plot_3d\n",
    "# import package functions\n",
    "from script_utils_CNV import get_CNVconfig, show_output\n",
    "\n",
    "\n",
    "# HOME\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "\n",
    "# standard paths\n",
    "static = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "PON_path = os.path.join(static, \"PON/HAEv7_hg38_NovaSeq\")\n",
    " \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "plot_path = os.path.join(cnvdata, \"plot\")\n",
    "fig_path = os.path.join(cnvdata, \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config = dict(\n",
    "        mawk_path=\"../shell\",\n",
    "        cov_path=os.path.join(output_path, \"pile2CNV\"),   # path containing rawcov.gz files for this sample\n",
    "        snp_path=os.path.join(output_path, \"pile2CNV\"),   # path containing snp files for this sample\n",
    "        bed_file=os.path.join(static, \"bed_files/SureSelect/hg38/SS_HAEv7_hg38_Padded.bed\"),\n",
    "        genome_split_path=os.path.join(static, \"genome/gatk/hg38/split\"),\n",
    "        gc_split_path=os.path.join(static, \"genome/gatk/hg38/split\"),\n",
    "        genmap_split_path=os.path.join(static, \"annotation/genmap/hg38/split\"),\n",
    "        PON_path = PON_path,\n",
    "    )\n",
    "CNVconfig = get_CNVconfig(\n",
    "    \"../config/config_CNV.yaml\", \n",
    "    local_config=path_config)\n",
    "CNVconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract blocks of CNV for clustering\n",
    "+ needs to be done before the fusing with SNP in order to make use of high definition diff\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocks(df, col, min_size=0):\n",
    "    '''\n",
    "    takes a column of binary containment to certain group and returns block numbers and respective block_sizes\n",
    "    excludes blocks below a certain block size limit\n",
    "    '''\n",
    "    \n",
    "    org_cols = list(df.columns)\n",
    "    # find gaps where col value changes\n",
    "    df.loc[:, ['gap']] = (df[col] != df.shift(1)[col]).astype(int)\n",
    "    # set the col names\n",
    "    blocksize = f'{col}block_size'\n",
    "    block = f'{col}block'\n",
    "    \n",
    "    # enumerate the gaps for blockID where value is 1\n",
    "    df.loc[:, [block]] = df['gap'].cumsum() * df[col]\n",
    "    # group by blocks and count size\n",
    "    blocks = df.groupby(block)['gap'].count().rename(blocksize)\n",
    "    # merge block size into df\n",
    "    df = df.merge(blocks, left_on=block, right_index=True)\n",
    "    # remove miniscule blocks\n",
    "    df.loc[df[blocksize] < min_size, block] = 0\n",
    "    \n",
    "    ### maybe adjust block labelling to be numerically ordered\n",
    "    # should maybe done \n",
    "    df.loc[:, col]  = df[block]\n",
    "    # cols = org_cols + [block, blocksize]\n",
    "    return df[org_cols]\n",
    "\n",
    "\n",
    "def get_CNV_blocks(df, data, config):\n",
    "    '''\n",
    "    finds blocks of CNV with center LLH below threshold\n",
    "    then it reduces these blocks to the regions within the Diff-peaks.. \n",
    "    ..to only enter the most meaningful data into clustering\n",
    "\n",
    "    do the same thing for covCenter with values above center threshold\n",
    "    (definitely belonging to the center)\n",
    "    '''\n",
    "\n",
    "    # extract params from config\n",
    "    # for covLLH --> lookup combine.cov.LLH_cutoff t=cov\n",
    "    t = data.replace('LLH', \"\")\n",
    "    params = config[t]\n",
    "\n",
    "    LLH_params = params['LLH_cutoff']\n",
    "\n",
    "    col = data + \"sum\"\n",
    "    diff_col = data + \"Diff\"\n",
    "\n",
    "    # get the covCNV\n",
    "\n",
    "    # get boolint whether LLH falls below threshold\n",
    "    # fillna(1) to exclude any missing coverages\n",
    "    df.loc[:, f'{t}CNV'] = (df[col].fillna(1) < LLH_params['cnv']).astype(int)\n",
    "    # get the covCNV blocks\n",
    "    df = get_blocks(df, f'{t}CNV', min_size=LLH_params['min_block_size'])\n",
    "    # reduce data to within Diff-peaks\n",
    "    df.loc[:, f'{t}CNVcore'] = ((df[f'{t}CNV'] > 0) & (\n",
    "        df[f'{t}LLHsumDiff'] < LLH_params['max_diff'])).astype(int)\n",
    "\n",
    "    # here I could also expand the covCNV to the peak of the Diff for covCNVexp\n",
    "    # get the window_size for core expanding\n",
    "    window_size = params['rolling_data'][data]['sum']\n",
    "\n",
    "    # get the covCenter\n",
    "    df.loc[:, f'{t}Center'] = (df[col].fillna(\n",
    "        0) > LLH_params['center']).astype(int)\n",
    "    # get the covCenter blocks\n",
    "    df = get_blocks(df, f'{t}Center', min_size=LLH_params['min_block_size'])\n",
    "    # reduce data to within Diff-peaks\n",
    "    df.loc[:, f'{t}Centercore'] = ((df[f'{t}Center'] > 0) & (\n",
    "        df[f'{t}LLHsumDiff'] < LLH_params['max_diff'])).astype(int)\n",
    "    # get the window_size for core expanding\n",
    "    window_size = params['rolling_data'][data]['sum']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_cov_df = get_CNV_blocks(rolling_cov_df, 'covLLH', config)\n",
    "df\n",
    "\n",
    "block_snp_df = get_CNV_blocks(snp_df, 'snpLLH', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d-plot snpVAF vs log2ratio and assign CNVstatus for individual blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  get the sample\n",
    "+ from the sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:10.715091Z",
     "start_time": "2020-12-17T07:09:10.689312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample(sample):\n",
    "    s = sample.replace(\"_\", \"\")\n",
    "    sample_df = pd.read_excel(os.path.join(wes_path, \"cluster_samples.xlsx\")).set_index('sample')\n",
    "    return sample_df.loc[s, \"file\"]\n",
    "\n",
    "get_sample(\"06A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:12.711926Z",
     "start_time": "2020-12-17T07:09:12.619264Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = \"06A\"\n",
    "cluster_df = pd.read_csv(get_sample(sample), sep='\\t')\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strategy\n",
    "+ get the means and sigma from the center_df\n",
    "+ adjust absVAF and log2ratio of CNV_df\n",
    "+ plot\n",
    "+ find most likely purity by llh2d_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:14.466792Z",
     "start_time": "2020-12-17T07:09:14.461445Z"
    }
   },
   "outputs": [],
   "source": [
    "def center_data(cluster_df):\n",
    "    '''\n",
    "    get the center_df containing only points belonging to both Centercores\n",
    "    '''\n",
    "    \n",
    "    cols = ['log2ratio', 'log2ratiomean', 'absVAF', 'absVAFmean']\n",
    "\n",
    "    # get the center_df with points belonging to both Centercores\n",
    "    center_df = cluster_df.query('covCentercore + snpCentercore == 2').copy()\n",
    "    # get the mean and std for relevant columns\n",
    "    center_params = center_df[cols + ['VAF']].agg(['mean', 'std']).T\n",
    "    # get the cnv_df with at least one CNVcore per point\n",
    "    cnv_df = cluster_df.query('snpCNVcore + covCNVcore > 0').copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        center_df.loc[:, col] = center_df[col] - center_params.loc[col, 'mean']\n",
    "        cnv_df.loc[:, col] = cnv_df[col] - center_params.loc[col, 'mean']\n",
    "        \n",
    "    cnv_df.loc[:, 'VAF'] = cnv_df['VAF'] + 0.5 - center_params.loc['VAF', 'mean']\n",
    "    center_df.loc[:, 'VAF'] = center_df['VAF'] + 0.5 - center_params.loc['VAF', 'mean']\n",
    "    return cnv_df, center_df, center_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:15.096747Z",
     "start_time": "2020-12-17T07:09:15.067843Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_df, center_df, center_params = center_data(cluster_df)\n",
    "center_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dimensional llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:16.173836Z",
     "start_time": "2020-12-17T07:09:16.170308Z"
    }
   },
   "outputs": [],
   "source": [
    "def llh2d(dx, dy, mx=0, my=0, sx=0.5, sy=0.1):\n",
    "    '''\n",
    "    compute the density function for a given gaussian\n",
    "    takes a pd.Series or np.array\n",
    "    '''   \n",
    "    # get the fixed term\n",
    "    s = 2 * np.pi * sx * sy\n",
    "    return np.exp((((dx - mx) / sx) **2 + ((dy - my) / sy) **2) / -2) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T20:52:20.562673Z",
     "start_time": "2020-11-14T20:52:20.559204Z"
    }
   },
   "source": [
    "### get all the means depending on alpha\n",
    "+ will be used for making gaussians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:17.307480Z",
     "start_time": "2020-12-17T07:09:17.263679Z"
    }
   },
   "outputs": [],
   "source": [
    "# start with a simple dataFrame\n",
    "import math\n",
    "\n",
    "def get_gauss_mask(alpha, Nmax):\n",
    "    '''\n",
    "    returns the gauss params for the gauss mask\n",
    "    '''\n",
    "    \n",
    "    alpha = min(1,alpha)\n",
    "    df = pd.DataFrame()\n",
    "    for n in range(int(Nmax)):\n",
    "        N = n + 1 \n",
    "        for i in range(math.ceil((N + 1) / 2)):\n",
    "            string = \"A\" * (N - i) + \"B\" * i\n",
    "            if string == 'A':\n",
    "                string = 'LOH'\n",
    "            absVAF = alpha * np.abs((2 * i) / N - 1)\n",
    "            log2 = np.log2(2 + alpha * (N - 2)) - 1\n",
    "            s = pd.Series({'type': string, 'absVAF': absVAF, 'log2ratio': log2})\n",
    "            df = df.append(s, ignore_index=True)\n",
    "    return df.query('(absVAF !=0 or log2ratio != 0) or type == \"AB\"')\n",
    "\n",
    "\n",
    "Nmax = 4\n",
    "alpha = 1\n",
    "gauss_mask = get_gauss_mask(alpha, Nmax)\n",
    "gauss_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ####  mask2VAF for converting to VAF gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:19.533780Z",
     "start_time": "2020-12-17T07:09:19.496233Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask2VAF(mask_df):\n",
    "    '''\n",
    "    converts the gauss_mask for absVAF into mask for VAF\n",
    "    '''\n",
    "    \n",
    "    df = mask_df.copy()\n",
    "    df.loc[:, 'VAF-'] = 0.5 - df['absVAF'] / 2\n",
    "    df.loc[:, 'VAF+'] = 0.5 + df['absVAF'] / 2\n",
    "    return df.loc[:, ['VAF-','VAF+', 'log2ratio', 'type']]\n",
    "\n",
    "\n",
    "def VAFmask(alpha, Nmax=6):\n",
    "    return mask2VAF(get_gauss_mask(alpha, Nmax))\n",
    "\n",
    "VAFmask(alpha, Nmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:24.134414Z",
     "start_time": "2020-12-17T07:09:24.121573Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "def plot_gaussian(df, xcol, ycol, \n",
    "                  df2=pd.DataFrame(), \n",
    "                  Nmax=0,   # maximal expected\n",
    "                  alpha=1,\n",
    "                  gauss_params=pd.DataFrame(), # the center_params containing the std\n",
    "                  logmax=2.5, \n",
    "                  std_factor = 1,\n",
    "                  rings=10, # number of rings for contour\n",
    "                  figsize=(6, 6)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    _ = ax.scatter(df[xcol], df[ycol], s=.1)\n",
    "    if len(df2.index):\n",
    "        _ = ax.scatter(df2[xcol], df2[ycol], s=2.5, alpha=.5, color='red')\n",
    "    _ = ax.set_xlabel(xcol, fontsize=15)\n",
    "    _ = ax.set_ylabel(ycol, fontsize=15)\n",
    "    _ = ax.set_title(f\"alpha={alpha}\", fontsize=20)\n",
    "    _ = sns.despine(ax=ax, offset=0)\n",
    "    _ = ax.spines['left'].set_position('zero')\n",
    "\n",
    "    \n",
    "    def get_lims(col):\n",
    "        if 'log' in col:\n",
    "            return (-1.5, logmax)\n",
    "        if 'VAF' in col:\n",
    "            return (-0.05, 1.05)\n",
    "    _ = ax.set_xlim(get_lims(xcol))\n",
    "    _ = ax.set_ylim(get_lims(ycol))\n",
    "    \n",
    "    # add gaussian mask\n",
    "    if Nmax:\n",
    "        # create the grid\n",
    "        x = np.linspace(*get_lims(xcol), 500)\n",
    "        y = np.linspace(*get_lims(ycol), 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "        \n",
    "        # get the std from the params\n",
    "        sx, sy = gauss_params.loc[[xcol, ycol], 'std']\n",
    "        print(sx, sy)\n",
    "        sx *= std_factor\n",
    "        sy *= std_factor\n",
    "        gaussians = get_gauss_mask(alpha, Nmax)\n",
    "        if xcol == 'VAF':\n",
    "            gaussians = mask2VAF(gaussians)\n",
    "            for _, row in gaussians.iterrows():\n",
    "                mx1 = row['VAF-']\n",
    "                mx2 = row['VAF+']\n",
    "                my = row['log2ratio']\n",
    "                Z += llh2d(X,Y, mx1, my, sx, sy) +   llh2d(X,Y, mx2, my, sx, sy)\n",
    "                ax.text(mx1, my-0.2, row['type'], ha='center')\n",
    "                # add the mirror cluster unless it is AB\n",
    "                if not row['type'] == \"AB\":\n",
    "                    ax.text(mx2, my-0.2, row['type'].replace('A', 'G').replace('B', 'A').replace('G', 'B'), ha='center')\n",
    "        else:\n",
    "            for _, row in gaussians.iterrows():\n",
    "                mx = row['absVAF']\n",
    "                my = row['log2ratio']\n",
    "                Z += llh2d(X,Y, mx, my, sx, sy)\n",
    "                ax.text(mx, my-0.2, row['type'], ha='center')\n",
    "        _ = ax.contour(X,Y,Z, rings, colors='black', alpha=1,linewidths=.4)\n",
    "    # set the y-spine\n",
    "    _ = ax.axhline(y=0, color='k')\n",
    "    _ = ax.axvline(x=0, color='k')\n",
    "    _ = ax.axvline(x=1, color='k')\n",
    "    if xcol == 'VAF':\n",
    "        _ = ax.axvline(x=0.5, c='k',ls=\"--\")\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:25.796804Z",
     "start_time": "2020-12-17T07:09:25.791915Z"
    }
   },
   "outputs": [],
   "source": [
    "log2 = dict(\n",
    "        title='log2ratio',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='log2ratio',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.3,\n",
    "            color='black',\n",
    "            s=2,\n",
    "            alpha=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "log2mean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomean',\n",
    "        plot_args=dict(\n",
    "            linewidth=2,\n",
    "            color='yellow',\n",
    "            alpha=1\n",
    "        )\n",
    "    )\n",
    "vaf = dict(\n",
    "        title='VAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='VAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='black',\n",
    "            s=3,\n",
    "            alpha=1\n",
    "        ))\n",
    "\n",
    "fig_params = dict(\n",
    "    figsize=(48,12),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(0,1),\n",
    "    cov_offset=.1,  # how much log2ratio=0 is shifted above SNP-data\n",
    "    cov_height=.5,\n",
    "    label_size=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:16:42.449311Z",
     "start_time": "2020-12-17T07:16:41.844001Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"04A\"\n",
    "cluster_df = pd.read_csv(get_sample(sample), sep='\\t')\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "cnv_df, center_df, center_params = center_data(cluster_df)\n",
    "fig, _, _, _ = plot_snp2(cluster_df, snp_plots=[vaf], cov_plots=[log2, log2mean], blocks=[\"snpCNVcore\", \"covCNVcore\"], chroms='all', region='chr7', **fig_params)\n",
    "# fig.savefig(os.path.join(f\"/Users/martinscience/Desktop/CNVAML/new/{sample}_blocks.jpg\"),pil_kwargs=dict(quality=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:16:55.040479Z",
     "start_time": "2020-12-17T07:16:55.035305Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_df['covCNV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:09:59.721388Z",
     "start_time": "2020-12-17T07:09:59.345634Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_df, center_df, center_params = center_data(cluster_df)\n",
    "xcol = 'VAF'\n",
    "ycol = 'log2ratiomean'\n",
    "fig, ax = plot_gaussian(center_df, df2=cnv_df, xcol=xcol, ycol=ycol, \n",
    "                        Nmax=4, \n",
    "                        rings=8, \n",
    "                        logmax=1.5,\n",
    "                        alpha=.85, \n",
    "                        std_factor=1,\n",
    "                        gauss_params=center_params\n",
    "                       )\n",
    "# fig.savefig(os.path.join(f\"/Users/martinscience/Desktop/CNVAML/new/{sample}_cluster.jpg\"),pil_kwargs=dict(quality=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do the block assignment according to LLH\n",
    "+ LLH2D computation has to be done for every possible gaussian\n",
    "+ data can be computed for entire CNV_df\n",
    "+ grouped sums can then be maximized\n",
    "+ center params are needed for gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:17:35.540533Z",
     "start_time": "2020-12-17T07:17:35.529326Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_means(row):\n",
    "    '''\n",
    "    row helper for extracting the means from the VAFmask after extraction of alpha and CNVstatus\n",
    "    '''\n",
    "    return VAFmask(float(row['a'])).set_index(\"type\").loc[row['type']]\n",
    "\n",
    "\n",
    "def get_all_means(df):\n",
    "    '''\n",
    "    retrieves the means for VAF and log2ratiomean from the CNVcall for visualization\n",
    "    '''\n",
    "    \n",
    "    df[['a', 'type']] = df['CNVcall'].str.extract(r\"([0-9.]+)-([ABLOH]+)\")\n",
    "    df[['VAF-', 'VAF+', 'log2ratio']] = df.apply(get_means, axis=1)\n",
    "    return df.drop(['a', 'type'], axis=1)\n",
    "\n",
    "\n",
    "def call_blocks(df, alpha=0.9, Nmax=6, center_params=pd.DataFrame()):\n",
    "    '''\n",
    "    takes a cluster_df and makes the CNV calls\n",
    "    1. computes the 2D-LLH for every given alpha and possible CNVstatus (VAF-symmetric)\n",
    "    2. assigns the CNV-status per group where the LLH-sum is maximal\n",
    "    3. outputs the blocks with CNV-status and imputed means for visualization\n",
    "    '''\n",
    "    # get the std from center_params\n",
    "    vaf_std = center_params.loc['VAF', 'std']\n",
    "    log2_std = center_params.loc['log2ratiomean', 'std']\n",
    "    \n",
    "    # force list for alpha\n",
    "    if not isinstance(alpha, list):\n",
    "        alpha = [alpha] \n",
    "    \n",
    "    # add a column for every CNV type and every alpha\n",
    "    # and calculate the respective \n",
    "    for a in alpha:\n",
    "        # cycle through the VAFmask (containing the means for the respective gaussians)\n",
    "        mask = VAFmask(a, Nmax)\n",
    "        for _, row in mask.iterrows():\n",
    "            df[f\"{a}-{row['type']}\"] = llh2d(df['VAF'],df['log2ratiomean'], mx=row['VAF-'], my=row['log2ratio'], sx=vaf_std, sy=log2_std)\n",
    "            df[f\"{a}-{row['type']}\"] += llh2d(df['VAF'],df['log2ratiomean'], mx=row['VAF+'], my=row['log2ratio'], sx=vaf_std, sy=log2_std)\n",
    "    \n",
    "    # reduce df to the sums of LLH per CNVtype\n",
    "    # reduce to required columns and group by snpCNV\n",
    "    cnv_df = df.loc[:, ['snpCNV'] + [f\"{a}-{m}\" for a in alpha for m in mask['type']]].groupby('snpCNV').sum()\n",
    "    \n",
    "    cnv_df['CNVcall'] = cnv_df.columns[np.argmax(cnv_df.values, axis=1)]\n",
    "    \n",
    "    # get the start and end coordinates for each group\n",
    "    region_df = df.loc[:, ['Chr', 'Pos', 'snpCNV']].groupby(['snpCNV', 'Chr'])['Pos'].agg([\"min\", \"max\"]).rename({'min':'Start', 'max': 'End'}, axis=1).reset_index('Chr')\n",
    "    \n",
    "    # merge the region into the cnv_df\n",
    "    block_df = cnv_df.merge(region_df, left_index=True, right_index=True).loc[:, ['Chr', 'Start', 'End', 'CNVcall']]\n",
    "    \n",
    "    # add the VAF and log2ratio means for \n",
    "    # sort the blocks using key callable for quick chrom sort\n",
    "    block_df = get_all_means(block_df).sort_values(by=['Chr', 'Start'], key=lambda x: x.astype(str).str.replace(\"chr\", \"\").str.replace(\"X\", \"23\").astype(int))\n",
    "    return block_df   # .loc[block_df['VAF-'] != 0.5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:17:36.714821Z",
     "start_time": "2020-12-17T07:17:36.137459Z"
    }
   },
   "outputs": [],
   "source": [
    "df = cnv_df.copy()\n",
    "block_df = call_blocks(df, [0.85, 0.4], 6, center_params)\n",
    "block_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T04:30:12.173329Z",
     "start_time": "2020-12-16T04:30:12.169498Z"
    }
   },
   "source": [
    "## look at different data and scale-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:19:31.896869Z",
     "start_time": "2020-12-16T11:19:30.805182Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"02A\"\n",
    "cluster_df = pd.read_csv(get_sample(sample), sep='\\t')\n",
    "\n",
    "fig, _, _, _ = plot_snp2(cluster_df, snp_plots=[vaf], cov_plots=[log2, log2mean], blocks=[\"snpCNVcore\", \"covCNVcore\"], chroms='all', region='', **fig_params)\n",
    "fig.savefig(os.path.join(f\"/Users/martinscience/Desktop/CNVAML/new/{sample}_blocks.jpg\"),pil_kwargs=dict(quality=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:19:55.699133Z",
     "start_time": "2020-12-16T11:19:52.669653Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_dff = cluster_df.copy()\n",
    "alpha = [.55,.7,.9]\n",
    "scale = .75\n",
    "shift = -.3\n",
    "cluster_dff['log2ratiomean'] = (cluster_dff['log2ratiomean'] + shift) * scale\n",
    "cnv_df, center_df, center_params = center_data(cluster_dff)\n",
    "cnv_df['log2ratiomean'] = (cnv_df['log2ratiomean'] + shift) * scale\n",
    "for a in alpha:\n",
    "    fig, ax = plot_gaussian(center_df, df2=cnv_df, xcol=xcol, ycol=ycol, \n",
    "                        Nmax=4, \n",
    "                        rings=8, \n",
    "                        logmax=1.5,\n",
    "                        alpha=a, \n",
    "                        std_factor=.7,\n",
    "                        gauss_params=center_params\n",
    "                       )\n",
    "    fig.savefig(os.path.join(f\"/Users/martinscience/Desktop/CNVAML/new/{sample}_{a}cluster.jpg\"),pil_kwargs=dict(quality=90))\n",
    "block_df = call_blocks(cnv_df, alpha, 6, center_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:20:03.284861Z",
     "start_time": "2020-12-16T11:20:03.274427Z"
    }
   },
   "outputs": [],
   "source": [
    "block_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:20:06.532560Z",
     "start_time": "2020-12-16T11:20:06.514401Z"
    }
   },
   "outputs": [],
   "source": [
    "block_df.to_csv(os.path.join(wes_path, get_sample(sample).replace(\".cluster\", \".CNVcall\")), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
