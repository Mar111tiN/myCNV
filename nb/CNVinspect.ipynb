{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:58:46.893611Z",
     "start_time": "2020-11-03T06:58:46.873532Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../codeCNV')\n",
    "from plot import plot_snp, plot_2d, plot_3d\n",
    "\n",
    "home = '/Users/mahtin'\n",
    "home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# load the config\n",
    "# edit config directly in yaml file\n",
    "import yaml\n",
    "config_file = '../config/config_devel.yaml'\n",
    "def get_config(config_file):\n",
    "        with open(config_file) as file:\n",
    "        # The FullLoader parameter handles the conversion from YAML\n",
    "        # scalar values to Python the dictionary format\n",
    "            config = yaml.load(file, Loader=yaml.FullLoader)['CNV']['cluster']\n",
    "        return config\n",
    "config = get_config(config_file)\n",
    "\n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the coverage and SNP data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vizualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:25:23.026048Z",
     "start_time": "2020-11-03T07:25:22.460476Z"
    }
   },
   "outputs": [],
   "source": [
    "log2 = dict(\n",
    "        title='log2ratio',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='log2ratio',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.3,\n",
    "            color='black',\n",
    "            s=0.2,\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "log2mean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='yellow',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "vaf = dict(\n",
    "        title='VAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='VAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            s=5,\n",
    "            alpha=.6\n",
    "        ))\n",
    "\n",
    "absvaf = dict(\n",
    "        title='VAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            s=5,\n",
    "            alpha=.6\n",
    "        ))\n",
    "\n",
    "\n",
    "absvafmean = dict(\n",
    "        title='deltaVAFvar',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='absVAFmean',\n",
    "        plot_args=dict(\n",
    "            linewidth=.5,\n",
    "            color='green',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "deltavafvar = dict(\n",
    "        title='deltaVAFvar',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='deltaVAFvar',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig_params = dict(\n",
    "    figsize=(44,8),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(0,1),\n",
    "    cov_offset=.1,  # how much log2ratio=0 is shifted above SNP-data\n",
    "    cov_height=.5,\n",
    "    label_size=13\n",
    ")\n",
    "sample = \"02_A\"\n",
    "snp_df = pd.read_csv(os.path.join(output_path, f'CNV/{sample}.roll.snp'), sep='\\t').dropna()\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "%matplotlib inline\n",
    "_ = plot_snp(snp_df, snp_plots=[vaf, absvafmean, deltavafvar], cov_plots=[log2, log2mean], chroms='all', region='', **fig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look where the bad stuff lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:25:28.304824Z",
     "start_time": "2020-11-03T07:25:28.137342Z"
    }
   },
   "outputs": [],
   "source": [
    "def region_query(region):\n",
    "    '''\n",
    "    function \n",
    "    '''\n",
    "\n",
    "    def convert(pos):\n",
    "        if pos.endswith('Mb'):\n",
    "            pos = int(float(pos.replace('Mb', '')) * 1e6)\n",
    "        elif pos.endswith('kb'):\n",
    "            pos = int(float(pos.replace('kb', '')) * 1000)\n",
    "        else:\n",
    "            pos = int(pos)\n",
    "        return pos\n",
    "\n",
    "    split = region.split(':')\n",
    "    chrom = split[0]\n",
    "\n",
    "    # if start and are used\n",
    "    if len(split) > 1 and '-' in split[1]:\n",
    "        se = split[1].split('-')\n",
    "        start = convert(se[0])\n",
    "        end = convert(se[1])\n",
    "    else:\n",
    "        start = 0\n",
    "        end = 1e10\n",
    "    return f'(Chr == \"{chrom}\" and {start} < Pos < {end})'\n",
    "\n",
    "def r_query(df, region_list):\n",
    "    '''\n",
    "    returns an or-combined pandas query for the regions in the list\n",
    "    '''\n",
    "    \n",
    "    r_query = \" or \".join([region_query(chrom) for chrom in [chr1, chr7, chr17]])\n",
    "    return df.query(r_query)\n",
    "\n",
    "chr1 = 'chr1:12790000-12800000'\n",
    "chr7 = 'chr7:101034000-101036000'\n",
    "chr17 = 'chr17:21415000-21416000'\n",
    "\n",
    "bad_df = r_query(snp_df, [chr1, chr7, chr17])\n",
    "xcol = 'log2ratiomean'\n",
    "ycol = 'deltaVAFvar'\n",
    "plot_2d(snp_df, df2=bad_df, xcol=xcol, ycol=ycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:25:50.021263Z",
     "start_time": "2020-11-03T07:25:49.866252Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_2d(snp_df, 'log2ratiomean', 'absVAFmean', df2=bad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:26:24.898307Z",
     "start_time": "2020-11-03T07:26:24.815117Z"
    }
   },
   "outputs": [],
   "source": [
    "colx = 'log2ratiomean'\n",
    "coly = 'deltaVAFvar'\n",
    "colz = 'absVAFmean'\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plot_3d(snp_df, df2=bad_df, xcol=colx, ycol=coly, zcol=colz, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out below average\n",
    "+ make a relative cutoff for all values of special data columns below a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:15:02.392605Z",
     "start_time": "2020-11-03T06:15:02.385163Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_threshold(snp_df, threshs={}):\n",
    "    '''\n",
    "    takes threshold dict {'log2ratio': [0.5, True], 'deltaVAFvar': [0.075, True]}\n",
    "    and returns \n",
    "    '''\n",
    "    df = snp_df.copy()\n",
    "    # mask is boolean series stating if snp is background\n",
    "    df['cnv'] = False\n",
    "    mask = df['cnv']\n",
    "    for col in threshs.keys():      \n",
    "        thresh = threshs[col][0] if threshs[col][1] else threshs[col][0] * df[col].max()\n",
    "        col_mask = np.abs(df[col]) > thresh\n",
    "        mask = mask | col_mask\n",
    "    df['cnv'] = mask.astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_df_by_thresholds(df, thresholds={}):\n",
    "    \n",
    "    # get the stringent from the threshold dict\n",
    "    cnv_thresholds = {}\n",
    "    for col in thresholds.keys():\n",
    "        cnv_thresholds[col] = thresholds[col][::2]\n",
    "    filter_df = filter_threshold(snp_df, threshs=cnv_thresholds).query('cnv == 1')\n",
    "    \n",
    "    # get the center mass\n",
    "    center_thresholds = {}\n",
    "    for col in thresholds.keys():\n",
    "        center_thresholds[col] = thresholds[col][1:]\n",
    "    center_df = filter_threshold(snp_df, threshs=center_thresholds).query('cnv == 0')\n",
    "\n",
    "    return filter_df, center_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:15:07.008657Z",
     "start_time": "2020-11-03T06:15:06.944811Z"
    }
   },
   "outputs": [],
   "source": [
    "config = get_config(config_file)\n",
    "config\n",
    "filter_df, center_df = split_df_by_thresholds(snp_df.query('Chr != \"chrX\"'), thresholds=config['thresholds'])\n",
    "plot_3d(center_df, df2=filter_df, xcol='log2ratiomean', ycol='absVAFmean', zcol='deltaVAFvar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE for cleaning up the filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:30:45.686963Z",
     "start_time": "2020-11-03T05:30:45.064590Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def clean_KDE(filter_df, cols, cleanup_density=0.25):\n",
    "    # prepare the matrix\n",
    "    df = filter_df.copy()\n",
    "    X = df[cols]\n",
    "    # gridsearch the best density params\n",
    "    bandwidths = np.logspace(-2, 0, 25)\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'),\n",
    "                    {'bandwidth': bandwidths},\n",
    "                    cv=7)\n",
    "    grid.fit(X)\n",
    "    # fit best model to data\n",
    "    kde = grid.best_estimator_\n",
    "    _ = kde.fit(X)\n",
    "    # get the densities for the samples\n",
    "    df['density'] = kde.score_samples(X)\n",
    "    # determine the threshold\n",
    "    thresh = df['density'].min() + (df['density'].max() -  df['density'].min()) * cleanup_density\n",
    "    return df.query('density < @thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:06:03.446505Z",
     "start_time": "2020-11-02T15:06:01.870948Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the matrix\n",
    "select_cols = ['log2ratiomean', 'absVAFmean', 'deltaVAFvar']\n",
    "\n",
    "clean_df = clean_KDE(filter_df, cols=select_cols, cleanup_density=.75)\n",
    "plot_3d(filter_df, df2=clean_df, xcol='log2ratiomean', ycol='absVAF', zcol='deltaVAFvar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit this cleaned set with GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T14:56:58.307793Z",
     "start_time": "2020-11-01T14:56:58.304124Z"
    }
   },
   "outputs": [],
   "source": [
    "select_cols = ['log2ratiomean', 'absVAF', 'deltaVAFvar']\n",
    "X = cleaned_df[select_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T15:34:38.122198Z",
     "start_time": "2020-11-01T15:34:37.809791Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import silhouette_score as ssc\n",
    "labels = GMM(n_components=2, covariance_type='diag', n_init=20).fit_predict(X)\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "xcol = 'log2ratiomean'\n",
    "ycol = 'deltaVAFvar'\n",
    "_ = ax.scatter(X[xcol], X[ycol], c=labels, s=1, cmap='viridis')\n",
    "_ = ax.set_xlabel(xcol, fontsize=10)\n",
    "_ = ax.set_ylabel(ycol, fontsize=10)\n",
    "\n",
    "print('Silhouette score: ', ssc(X, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T15:01:30.306604Z",
     "start_time": "2020-11-01T15:01:30.090948Z"
    }
   },
   "source": [
    "### find the optimal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T15:36:56.492446Z",
     "start_time": "2020-11-01T15:36:54.447366Z"
    }
   },
   "outputs": [],
   "source": [
    "n_components = np.arange(2, 10)\n",
    "models = [GMM(n, covariance_type='full', n_init=20).fit(X)\n",
    "          for n in n_components]\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "_ = ax.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "_ = ax.plot(n_components, [ssc(X, m.predict(X), metric='euclidean') * -5000 for m in models], label='SilScore')\n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlabel('n_components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T15:40:05.780551Z",
     "start_time": "2020-11-01T15:40:05.541070Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "select_cols = ['log2ratiomean', 'absVAF', 'deltaVAFvar']\n",
    "X = filter_df[select_cols]\n",
    "rows = X.shape[0]\n",
    "ep=0.2\n",
    "ms = int(rows/20)\n",
    "\n",
    "labels = DBSCAN(eps=ep, min_samples=ms).fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN for finding the clusters and reducing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:07:37.106422Z",
     "start_time": "2020-10-31T07:07:36.916671Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# get the matrix\n",
    "allcols = ['log2ratiomean', 'VAF', 'absVAF', 'deltaVAFstd', 'deltaVAFvar', 'VAFstd']\n",
    "select_cols = ['log2ratiomean', 'absVAF', 'deltaVAFvar']\n",
    "X = filter_df[select_cols]\n",
    "rows = X.shape[0]\n",
    "\n",
    "ep=0.1\n",
    "ms = int(rows/20)\n",
    "\n",
    "labels = DBSCAN(eps=ep, min_samples=ms).fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')\n",
    "cluster, counts = np.unique(labels, return_counts=True)\n",
    "cluster_count = len(cluster[cluster != -1])\n",
    "cluster_size = counts[np.argmax(counts)]\n",
    "cluster_id = cluster[np.argmax(counts)]\n",
    "print(f\"ep:{round(ep,2)}|min_samples:{ms}>> {cluster_count} clusters | cluster{cluster_id}: {cluster_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:18:05.837864Z",
     "start_time": "2020-10-31T07:18:05.831437Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_DBSCAN(X, max_cluster=1, eps=np.logspace(-1,1,10), sample_fracs=np.logspace(-3,-1,10)):\n",
    "    max_counts = 0\n",
    "    for sample_frac in sample_fracs:\n",
    "        for ep in eps:\n",
    "            # sample_fraction up to all samples if wanted\n",
    "            ms = min(X.shape[0], int(X.shape[0] * sample_frac))\n",
    "            model = DBSCAN(eps=ep, min_samples=ms)\n",
    "            labels = model.fit_predict(X)\n",
    "            cluster, counts = np.unique(labels, return_counts=True)\n",
    "            # get the number of clusters \n",
    "            cluster_count = len(cluster[cluster != -1])\n",
    "            # get the size of cluster 0\n",
    "            #! maybe use better with largest cluster\n",
    "            cluster_size = counts[np.argmax(counts)]\n",
    "            if cluster_count:\n",
    "                if cluster_size > max_counts:\n",
    "                    best_model = model\n",
    "                    print(f\"Best model: ep:{round(ep,2)}|min_samples:{ms}>> {cluster_count} clusters | cluster0: {cluster_size}\")\n",
    "                    if (cluster_count <= max_cluster):\n",
    "                        best_limit_model = model      \n",
    "                        print(f\"BEST model: ep:{round(ep,2)}|min_samples:{ms}>> {cluster_count} clusters | cluster0: {cluster_size}\")\n",
    "    return best_model, best_limit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:18:27.691924Z",
     "start_time": "2020-10-31T07:18:27.138800Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model, best_limit_model = fit_DBSCAN(X, max_cluster=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:18:56.406528Z",
     "start_time": "2020-10-31T07:18:56.220303Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = best_model.fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:02:13.361689Z",
     "start_time": "2020-10-31T07:02:13.355500Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the matrix from the df\n",
    "allcols = ['log2ratiomean', 'VAF', 'absVAF', 'deltaVAFstd', 'deltaVAFvar', 'VAFstd']\n",
    "select_cols = ['log2ratiomean', 'absVAF', 'deltaVAFvar']\n",
    "X = filter_df[select_cols]\n",
    "rows = X.shape[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### GMM clustering runs best for fitting the center mass\n",
    "    * clusters vary depending on init clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:02:16.098118Z",
     "start_time": "2020-10-31T07:02:14.974165Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=3, covariance_type='diag', n_init=20)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    _ = axes[i].scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "def get_centers(df, runs=25, comps=3, exclude_X=True, cols=['log2ratiomean', 'VAF']):\n",
    "    '''\n",
    "    use GMM to identify the center cluster and get the means from that\n",
    "    because GMM occasionally does not identify the center cluster,\n",
    "    I let the GMM proceed several times and minimize the center cluster\n",
    "    next, the center cluster can be identified as the maximum center\n",
    "    '''\n",
    "    VAFmin, VAFmax = VAF_limits\n",
    "    # fit the centers to the data \n",
    "    if exclude_X:\n",
    "        df = df.query('Chr != \"chrX\"')     \n",
    "    X = df[cols]\n",
    "\n",
    "    gmm = GMM(n_components=comps, covariance_type='diag', n_init=runs).fit(X)\n",
    "    labels = gmm.predict(X)\n",
    "    # get the size of the \n",
    "    cluster_id, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    print(cluster_id, counts, gmm.means_)\n",
    "    maxcount = np.max(counts)\n",
    "    centers = pd.DataFrame(gmm.means_, columns=['log2ratio', 'VAF'])\n",
    "    # get mean_cov and meanVAF from largest cluster\n",
    "    meanCov, meanVAF = centers.loc[np.argmax(counts)]\n",
    "    size = maxcount\n",
    "            \n",
    "    print(f'GMM using {runs} inits: center size {size} meanVAF = {round(meanVAF, 2)} meanCov={round(meanCov, 2)}')\n",
    "    \n",
    "    return meanCov, meanVAF, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T16:05:23.872063Z",
     "start_time": "2020-10-30T16:05:23.868821Z"
    }
   },
   "outputs": [],
   "source": [
    "24000 / 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T07:02:27.008832Z",
     "start_time": "2020-10-31T07:02:26.821520Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading labels back into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T16:08:03.314466Z",
     "start_time": "2020-10-30T16:08:03.275738Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df['dbscan'] = labels\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T16:11:51.074393Z",
     "start_time": "2020-10-30T16:11:50.324458Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df.to_csv(os.path.join(output_path, f'cluster/{sample}.dbscan.csv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T19:00:16.459062Z",
     "start_time": "2020-10-29T19:00:16.454940Z"
    }
   },
   "outputs": [],
   "source": [
    "counts[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### DBSCAN seems to be best fitted for removing the center mass as the spread is hard to guess\n",
    "    * perform a grid search on eps and min_samples to find the maximum center mass with just one cluster\n",
    "    * better!: perform this grid search on multi-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:33:09.819042Z",
     "start_time": "2020-10-29T18:33:09.812401Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:45:25.241478Z",
     "start_time": "2020-10-29T18:33:10.465523Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T19:38:55.661022Z",
     "start_time": "2020-10-29T19:38:45.246489Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T19:01:18.641224Z",
     "start_time": "2020-10-29T19:01:18.636612Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:58:37.942768Z",
     "start_time": "2020-10-29T18:58:28.844551Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = best_limit_model.fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T18:59:49.832306Z",
     "start_time": "2020-10-29T18:59:49.827153Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:10:19.677814Z",
     "start_time": "2020-10-29T07:10:19.647656Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df['DBID'] = labels\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:10:28.649883Z",
     "start_time": "2020-10-29T07:10:28.621978Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_df = snp_df.query('DBID > 0')\n",
    "cnv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:16:37.699619Z",
     "start_time": "2020-10-29T07:16:37.692699Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_params = dict(\n",
    "    figsize=(24,8),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(0,1),\n",
    "    cov_offset=.1,  # how much log2ratio=0 is shifted above SNP-data\n",
    "    cov_height=.5,\n",
    "    label_size=13\n",
    ")\n",
    "\n",
    "log2 = dict(\n",
    "        title='log2ratio',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='log2ratio',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.3,\n",
    "            color='black',\n",
    "            s=0.2,\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "log2mean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='yellow',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',  # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        cluster={'DBID', 'blue'}\n",
    "        plot_args=dict(\n",
    "            s=1,\n",
    "            c=snp_df.query('Chr in @chroms')['DBID'],\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_snp(snp_df, snp_plots=[absvaf], cov_plots=[log2, log2mean], chroms=chroms, region='', **fig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ increasing n_init to 20 does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:57:27.687791Z",
     "start_time": "2020-10-28T10:57:19.683641Z"
    }
   },
   "outputs": [],
   "source": [
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=3, covariance_type='diag', n_init=25)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    _ = axes[i].scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
