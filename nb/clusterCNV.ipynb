{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:21:47.082338Z",
     "start_time": "2020-10-28T21:21:46.519378Z"
    }
   },
   "outputs": [],
   "source": [
    "# HOME\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "# get the code\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from plot import plot_snp\n",
    "\n",
    "home = '/Users/mahtin'\n",
    "# home = '/Users/martinscience'\n",
    "# standard paths\n",
    "testdata = os.path.join(home,\"Dropbox/Icke/Work/somVar/testdata\")\n",
    "static_path = os.path.join(home, \"Dropbox/Icke/Work/static\")\n",
    "cluster_path = os.path.join(home, \"mount\")\n",
    "tooldata = os.path.join(home, \"Dropbox/Icke/Work/somVar/tooldata\")\n",
    "\n",
    "# tool-specific paths\n",
    "shell_path = \"../shell\"\n",
    "# \n",
    "cnvdata = os.path.join(tooldata, \"myCNVdata\")\n",
    "output_path = os.path.join(cnvdata, \"output\")\n",
    "\n",
    "# the path to the input data\n",
    "cnv_path = os.path.join(cnvdata, \"cnv\")\n",
    "cnvPON_path = cnv_path = os.path.join(cnvdata, \"chromCov\")\n",
    "cnv_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/cnv\")\n",
    "cnvPON_path = os.path.join(cluster_path, \"scratch/develop/PONcoverage/chromCov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:21:48.189482Z",
     "start_time": "2020-10-28T21:21:48.183999Z"
    }
   },
   "outputs": [],
   "source": [
    "cnvPON_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the coverage and SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:22:00.003110Z",
     "start_time": "2020-10-28T21:21:59.887545Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = \"01_A\"\n",
    "snp_df = pd.read_csv(os.path.join(output_path, f'rollingCNV/{sample}.snp.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:09:28.899157Z",
     "start_time": "2020-10-28T22:09:28.859826Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df = snp_df.dropna()\n",
    "snp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heteroSNP rolling window\n",
    "+ #### first, the center cluster has to be fitted via clustering to identify the centers for mean correction\n",
    "+ #### look at the distribution of VAF and rolling log2ratio\n",
    "+ #### chrX seems to have different log2ratio (maybe adjusted for XX and XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:28:26.321866Z",
     "start_time": "2020-10-28T21:28:26.163587Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(snp_df['log2ratiomean'], snp_df['VAFstd'], s=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T21:29:49.471145Z",
     "start_time": "2020-10-28T21:29:42.494414Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# get the matrix\n",
    "cols = ['log2ratiomean', 'absVAF', 'deltaVAFstd', 'deltaVAFvar', 'VAFstd']\n",
    "X = snp_df[['log2ratiomean', 'absVAF', 'deltaVAFstd', 'deltaVAFvar', 'VAFstd']].dropna()\n",
    "rows = X.shape[0]\n",
    "labels = DBSCAN(eps=.2, min_samples=int(rows/3.5)).fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')\n",
    "cluster, counts = np.unique(labels, return_counts=True)\n",
    "len(cluster[cluster != -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### DBSCAN seems to be best fitted for removing the center mass as the spread is hard to guess\n",
    "    * perform a grid search on eps and min_samples to find the maximum center mass with just one cluster\n",
    "    * better!: perform this grid search on multi-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:02:39.754436Z",
     "start_time": "2020-10-28T21:57:04.656029Z"
    }
   },
   "outputs": [],
   "source": [
    " max_counts = 0\n",
    "for sample_frac in np.linspace(50,200,4):\n",
    "    for ep in np.logspace(-.5,2,4):\n",
    "        ms = int(X.shape[0] / sample_frac)\n",
    "        model = DBSCAN(eps=0.2, min_samples=ms)\n",
    "        labels = model.fit_predict(X)\n",
    "        cluster, counts = np.unique(labels, return_counts=True)\n",
    "        # get the number of clusters \n",
    "        cluster_count = len(cluster[cluster != -1])\n",
    "        # get the size of cluster 0\n",
    "        cluster_size = counts[cluster == 0]\n",
    "        if cluster_count:\n",
    "            if cluster_size > max_counts:\n",
    "                best_model = model\n",
    "        print(f\"ep:{ep}|min_samples:{ms}>> {cluster_count} clusters | cluster0: {cluster_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:04:44.329346Z",
     "start_time": "2020-10-28T22:04:37.320348Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = best_model.fit_predict(X)\n",
    "plt.scatter(X['log2ratiomean'], X['absVAF'], c=labels, s=1, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:04:48.885169Z",
     "start_time": "2020-10-28T22:04:48.872063Z"
    }
   },
   "outputs": [],
   "source": [
    "X[labels != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:09:38.570581Z",
     "start_time": "2020-10-28T22:09:38.566629Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df['DBID'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:10:01.334272Z",
     "start_time": "2020-10-28T22:10:01.303295Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_df = snp_df.query('DBID > 0')\n",
    "cnv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T22:13:25.378127Z",
     "start_time": "2020-10-28T22:13:24.954888Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_params = dict(\n",
    "    figsize=(24,8),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(0,1),\n",
    "    cov_offset=.1,  # how much log2ratio=0 is shifted above SNP-data\n",
    "    cov_height=.5,\n",
    "    label_size=13\n",
    ")\n",
    "\n",
    "log2 = dict(\n",
    "        title='log2ratio',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='log2ratio',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.3,\n",
    "            color='black',\n",
    "            s=0.2,\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "log2mean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='log2ratiomean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='yellow',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',  # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            s=.2,\n",
    "            color='black',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_snp(cnv_df, snp_plots=[absvaf], cov_plots=[log2, log2mean], chroms='all', region='', **fig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### GMM clustering runs best for fitting the center mass\n",
    "    * clusters vary depending on init clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:56:57.136487Z",
     "start_time": "2020-10-28T10:56:54.967945Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "X = merge[['log2ratiomean', 'VAF']]\n",
    "X\n",
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=3, covariance_type='diag', n_init=2)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    _ = axes[i].scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ increasing n_init to 20 does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:57:27.687791Z",
     "start_time": "2020-10-28T10:57:19.683641Z"
    }
   },
   "outputs": [],
   "source": [
    "choice = range(5)\n",
    "fig, axes = plt.subplots(1, len(choice), figsize=(20,5))\n",
    "for i, components in enumerate(choice):\n",
    "    gmm = GMM(n_components=3, covariance_type='diag', n_init=25)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    print(np.max(counts))\n",
    "    _ = axes[i].scatter(X['log2ratiomean'], X['VAF'], c=labels, s=1)\n",
    "    # print(f'{components} components - AIC:', gmm.aic(X))\n",
    "    # print(f'{components} components - BIC:', gmm.bic(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T17:59:34.654063Z",
     "start_time": "2020-10-26T17:59:34.649723Z"
    }
   },
   "source": [
    "+ get_centers computes the means from the best fit centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:53.126987Z",
     "start_time": "2020-10-28T12:00:52.793086Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "def get_centers(merge_df, runs=25, comps=3, VAF_limits=(0.05, 0.95), exclude_X=True):\n",
    "    '''\n",
    "    use GMM to identify the center cluster and get the means from that\n",
    "    because GMM occasionally does not identify the center cluster,\n",
    "    I let the GMM proceed several times and minimize the center cluster\n",
    "    next, the center cluster can be identified as the maximum center\n",
    "    '''\n",
    "    VAFmin, VAFmax = VAF_limits\n",
    "    # fit the centers to the data \n",
    "    if exclude_X:\n",
    "        merge_df = merge_df.query('Chr != \"chrX\"')     \n",
    "    X = merge_df.query('@VAFmin < VAF < @VAFmax and log2ratiomean == log2ratiomean')[['log2ratiomean', 'VAF']]\n",
    "\n",
    "    gmm = GMM(n_components=comps, covariance_type='diag', n_init=runs).fit(X)\n",
    "    labels = gmm.predict(X)\n",
    "    # get the size of the \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    maxcount = np.max(counts)\n",
    "    centers = pd.DataFrame(gmm.means_, columns=['log2ratio', 'VAF'])\n",
    "    # get mean_cov and meanVAF from largest cluster\n",
    "    meanCov, meanVAF = centers.loc[np.argmax(counts)]\n",
    "    size = maxcount\n",
    "            \n",
    "    print(f'GMM using {runs} inits: center size {size} meanVAF = {round(meanVAF, 2)} meanCov={round(meanCov, 2)}')\n",
    "    \n",
    "    return meanCov, meanVAF, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:53.484840Z",
     "start_time": "2020-10-28T12:00:53.456063Z"
    }
   },
   "outputs": [],
   "source": [
    "meanCov, meanVAF, centers = get_centers(merge)\n",
    "meanVAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:53.931648Z",
     "start_time": "2020-10-28T12:00:53.926538Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'debug': False, # also export the left and right rolling window values (L/R)\n",
    "    'coverage': {\n",
    "        'filter': dict(\n",
    "            min_cov = 30,\n",
    "            min_PON_cov = 50,\n",
    "            max_PON_std = 100,\n",
    "        ),\n",
    "        'normalize':False,\n",
    "        'center': True,\n",
    "        'expand':0.2, # after interpolation of rolling data from filtered df into full df, interpolate missing data within this fraction of window size, set 0 if no interpolation is wanted\n",
    "        'data': {\n",
    "            'log2ratio': {\n",
    "                'mean':100\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'heteroSNP': {\n",
    "        'filter': dict(\n",
    "            VAF=(0.05,0.95),\n",
    "            minDepth=30,\n",
    "            minEB=0.5\n",
    "        ),\n",
    "        'normalize': True,\n",
    "        'center':False,\n",
    "        'expand': 0.5,\n",
    "        'data': {\n",
    "            'absVAF': {\n",
    "                'sum': 20\n",
    "            },\n",
    "            'VAF': {\n",
    "                'std': 20\n",
    "            },\n",
    "            'deltaVAF': {\n",
    "                'std': 20\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def center_data(snp_df, config):\n",
    "    '''\n",
    "    retrieve the centers for scaling using GMM\n",
    "    '''\n",
    "    \n",
    "    meanCov, meanVAF, _ = get_centers(snp_df, VAF_limits=config['heteroSNP']['filter']['VAF'])\n",
    "    # center coverage \n",
    "    if config['coverage']['center']:\n",
    "        print(\"log2ratio centered around\", meanCov)\n",
    "        snp_df.loc[:, 'log2ratiomean'] = snp_df['log2ratiomean'] - meanCov\n",
    "    if config['heteroSNP']['center']:\n",
    "        print(\"heteroSNP centered around\", meanVAF)\n",
    "        snp_df.loc[:, 'VAF'] = snp_df['VAF'] - meanVAF + 0.5\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:56.162000Z",
     "start_time": "2020-10-28T12:00:54.693089Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_df = center_data(snp_df, config)\n",
    "snp_df.query('log2ratiomean != log2ratiomean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:57.252438Z",
     "start_time": "2020-10-28T12:00:57.248210Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_SNPdata(snp_df, config):\n",
    "    '''\n",
    "    retrieve a few data columns locally to use rolling windows on\n",
    "    this needs to be done chromosome-wise in order to avoid gap effects\n",
    "    '''\n",
    "    \n",
    "    # get the new features from VAFs\n",
    "    snp_df.loc[:,'absVAF'] = np.abs(snp_df['VAF'] - 0.5) * 2\n",
    "    # get the local VAF difference chrom based\n",
    "    dfs = []\n",
    "    for chrom in snp_df['Chr'].unique():\n",
    "        chrom_df = snp_df.query('Chr == @chrom')\n",
    "        chrom_df.loc[:, 'deltaVAF'] = np.abs(chrom_df['VAF'] - chrom_df.shift(1)['VAF']).fillna(0)\n",
    "        dfs.append(chrom_df)\n",
    "    snp_df = pd.concat(dfs).sort_values('FullExonPos')\n",
    "    return snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:00:58.436170Z",
     "start_time": "2020-10-28T12:00:58.023464Z"
    }
   },
   "outputs": [],
   "source": [
    "snp2_df = expand_SNPdata(snp_df, config)\n",
    "snp2_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:01:57.643434Z",
     "start_time": "2020-10-28T12:01:56.932235Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_params = dict(\n",
    "    figsize=(24,8),\n",
    "    colormap='coolwarm_r',\n",
    "    color_chroms=True,\n",
    "    ylim=(0,1),\n",
    "    cov_offset=.1,  # how much log2ratio=0 is shifted above SNP-data\n",
    "    cov_height=.5,\n",
    "    label_size=13\n",
    ")\n",
    "\n",
    "vaf = dict(\n",
    "        title='VAF',\n",
    "        plot_type='scatter',  # ['line', 'scatter']\n",
    "        data='VAF',\n",
    "        plot_args=dict(\n",
    "            s=.2,\n",
    "            color='black',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))\n",
    "deltavaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='deltaVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='green',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_snp(snp2_df, snp_plots=[deltavaf, absvaf], cov_plots=[log2, log2mean], chroms=chroms, region='chr7', **fig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:02:05.530234Z",
     "start_time": "2020-10-28T12:02:05.524161Z"
    }
   },
   "outputs": [],
   "source": [
    "def rolling_snp(snp_df, config):\n",
    "    '''\n",
    "    cycle through the chroms and perform rolling window computations of snp data set in config\n",
    "    '''\n",
    "    \n",
    "    # split the params dict for easier access\n",
    "    params = config['heteroSNP']\n",
    "    filter_params = params['filter']\n",
    "    data_params = params['data']\n",
    "    # reduce the snp_df using config limits\n",
    "    VAFmin, VAFmax = filter_params['VAF'] \n",
    "    minDepth = filter_params['minDepth']\n",
    "    minEBscore = filter_params['minEB']\n",
    "    \n",
    "    # cycle through chroms for \n",
    "    chrom_dfs = []\n",
    "    for chrom in snp_df['Chr'].unique():\n",
    "        # restrict to chrom\n",
    "        chrom_df = snp_df.query('Chr == @chrom').sort_values('FullExonPos')        \n",
    "        # filter df\n",
    "        filter_df = snp_df.query('@VAFmin < VAF < @VAFmax and Depth >= @minDepth and EBscore > @minEBscore')\n",
    "        for data_col in data_params.keys():\n",
    "            for agg in data_params[data_col].keys():\n",
    "                window_size = data_params[data_col][agg]\n",
    "                expand_limit = int(params['expand'] * window_size)\n",
    "                # print(f\"Computing rolling window for {agg} of {data_col} with window size {window_size} on {chrom}\")\n",
    "                chrom_df = one_col_rolling(chrom_df, filter_df, data_col, agg, window_size=window_size, expand_limit=expand_limit, normalize=params['normalize'], debug=config['debug'])\n",
    "        chrom_dfs.append(chrom_df)\n",
    "    df = pd.concat(chrom_dfs).sort_values('FullExonPos')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T12:02:10.647366Z",
     "start_time": "2020-10-28T12:02:06.783534Z"
    }
   },
   "outputs": [],
   "source": [
    "snp_config = {\n",
    "    'heteroSNP': {\n",
    "        'filter': dict(\n",
    "            VAF=(0.05,0.95),\n",
    "            minDepth=30,\n",
    "            minEB=0.5\n",
    "        ),\n",
    "        'normalize': True,\n",
    "        'center':False,\n",
    "        'expand': 0.5,\n",
    "        'data': {\n",
    "            'absVAF': {\n",
    "                'sum': 20\n",
    "            },\n",
    "            'VAF': {\n",
    "                'std': 20\n",
    "            },\n",
    "            'deltaVAF': {\n",
    "                'std': 20\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "}\n",
    "\n",
    "config.update(snp_config)\n",
    "\n",
    "snp3_df = rolling_snp(snp2_df, config)\n",
    "snp3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizing rolling windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### absVAF\n",
    "+ mean\n",
    "+ std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T11:59:35.626216Z",
     "start_time": "2020-10-28T11:59:32.466002Z"
    }
   },
   "outputs": [],
   "source": [
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))\n",
    "\n",
    "absvafmean = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='absVAFmean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='yellow',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "\n",
    "absvafdiff = dict(\n",
    "        title='rollinglog2ratio',\n",
    "        plot_type='line',   # ['line', 'scatter']\n",
    "        data='absVAFmean',\n",
    "        plot_args=dict(\n",
    "            linewidth=1,\n",
    "            color='blue',\n",
    "            alpha=.7\n",
    "        )\n",
    "    )\n",
    "snp_config = {\n",
    "    'heteroSNP': {\n",
    "        'filter': dict(\n",
    "            VAF=(0.05,0.95),\n",
    "            minDepth=30,\n",
    "            minEB=0.5\n",
    "        ),\n",
    "        'normalize': True,\n",
    "        'center':False,\n",
    "        'expand': 1,\n",
    "        'data': {\n",
    "            'absVAF': {\n",
    "                'mean':50,\n",
    "                'sum': 50\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "}\n",
    "\n",
    "config.update(snp_config)\n",
    "snp3_df = rolling_snp(snp2_df, config)\n",
    "\n",
    "chroms = ['chr5', 'chr7','chr8', 'chr11', 'chr17']\n",
    "r1 = 'chr17:3Mb-9Mb'\n",
    "\n",
    "fig, ax, df, chrom_df = plot_snp(snp3_df, snp_plots=[absvaf,absvafmean, absvafdiff], chroms=chroms, region='chr17', **fig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absvaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='absVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='blue',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))\n",
    "deltavaf = dict(\n",
    "        title='absVAF',\n",
    "        plot_type='scatter',   # ['line', 'scatter']\n",
    "        data='deltaVAF',\n",
    "        plot_args=dict(\n",
    "            linewidth=0.5,\n",
    "            color='green',\n",
    "            s=5,\n",
    "            alpha=1\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
